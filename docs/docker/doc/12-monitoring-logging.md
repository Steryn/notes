# Dockerç›‘æŽ§ä¸Žæ—¥å¿—

## ðŸŽ¯ å­¦ä¹ ç›®æ ‡

- æ·±å…¥ç†è§£Dockerç›‘æŽ§ä½“ç³»å’Œæ—¥å¿—ç®¡ç†
- æŽŒæ¡Prometheusã€Grafanaç­‰ç›‘æŽ§å·¥å…·çš„ä½¿ç”¨
- å­¦ä¼šè®¾è®¡é«˜æ•ˆçš„æ—¥å¿—æ”¶é›†å’Œåˆ†æžç³»ç»Ÿ
- äº†è§£å‘Šè­¦æœºåˆ¶å’Œæ•…éšœæŽ’é™¤æµç¨‹

## ðŸ“š ç›‘æŽ§ä¸Žæ—¥å¿—æ¦‚è¿°

### 1. ç›‘æŽ§ä½“ç³»æž¶æž„

```javascript
// Dockerç›‘æŽ§ä½“ç³»
const dockerMonitoring = {
  metrics_layers: {
    infrastructure: {
      description: 'åŸºç¡€è®¾æ–½å±‚ç›‘æŽ§',
      targets: ['CPUä½¿ç”¨çŽ‡', 'å†…å­˜ä½¿ç”¨çŽ‡', 'ç£ç›˜I/O', 'ç½‘ç»œæµé‡'],
      tools: ['node-exporter', 'cadvisor', 'docker stats']
    },
    
    container: {
      description: 'å®¹å™¨å±‚ç›‘æŽ§',
      targets: ['å®¹å™¨çŠ¶æ€', 'èµ„æºé™åˆ¶', 'é‡å¯æ¬¡æ•°', 'å¥åº·æ£€æŸ¥'],
      tools: ['docker metrics', 'cadvisor', 'container-exporter']
    },
    
    application: {
      description: 'åº”ç”¨å±‚ç›‘æŽ§',
      targets: ['å“åº”æ—¶é—´', 'åžåé‡', 'é”™è¯¯çŽ‡', 'ä¸šåŠ¡æŒ‡æ ‡'],
      tools: ['åº”ç”¨metrics', 'APMå·¥å…·', 'è‡ªå®šä¹‰ç›‘æŽ§']
    },
    
    business: {
      description: 'ä¸šåŠ¡å±‚ç›‘æŽ§',
      targets: ['ç”¨æˆ·è¡Œä¸º', 'ä¸šåŠ¡æµç¨‹', 'SLAæŒ‡æ ‡', 'KPIç›‘æŽ§'],
      tools: ['ä¸šåŠ¡ç›‘æŽ§ç³»ç»Ÿ', 'æ•°æ®åˆ†æžå¹³å°']
    }
  },
  
  logging_types: {
    system_logs: 'ç³»ç»Ÿæ—¥å¿— - syslog, kern.log',
    container_logs: 'å®¹å™¨æ—¥å¿— - stdout/stderr',
    application_logs: 'åº”ç”¨æ—¥å¿— - ä¸šåŠ¡æ—¥å¿—',
    audit_logs: 'å®¡è®¡æ—¥å¿— - å®‰å…¨å’Œåˆè§„'
  },
  
  observability_pillars: [
    'Metrics - æŒ‡æ ‡ç›‘æŽ§',
    'Logging - æ—¥å¿—è®°å½•', 
    'Tracing - é“¾è·¯è¿½è¸ª'
  ]
};

console.log('Dockerç›‘æŽ§ä½“ç³»:', dockerMonitoring);
```

### 2. ç›‘æŽ§æŒ‡æ ‡ä½“ç³»

```yaml
# monitoring-metrics.yml
metrics_categories:
  system_metrics:
    cpu:
      - cpu_usage_percent
      - cpu_load_average
      - cpu_context_switches
    memory:
      - memory_usage_bytes
      - memory_available_bytes
      - memory_cached_bytes
      - memory_swap_usage
    disk:
      - disk_usage_percent
      - disk_io_read_bytes
      - disk_io_write_bytes
      - disk_io_operations
    network:
      - network_receive_bytes
      - network_transmit_bytes
      - network_receive_packets
      - network_transmit_packets

  container_metrics:
    resources:
      - container_cpu_usage_percent
      - container_memory_usage_bytes
      - container_memory_limit_bytes
      - container_blkio_read_bytes
      - container_blkio_write_bytes
    status:
      - container_up
      - container_restart_count
      - container_exit_code
      - container_start_time

  application_metrics:
    performance:
      - http_request_duration_seconds
      - http_requests_total
      - http_request_size_bytes
      - http_response_size_bytes
    errors:
      - error_rate
      - error_count_by_type
      - timeout_count
    business:
      - user_login_count
      - order_count
      - payment_success_rate
```

## ðŸ“Š Prometheusç›‘æŽ§ç³»ç»Ÿ

### 1. Prometheusé…ç½®

```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'docker-swarm'
    environment: 'production'

# å‘Šè­¦è§„åˆ™æ–‡ä»¶
rule_files:
  - "alert_rules.yml"
  - "recording_rules.yml"

# å‘Šè­¦ç®¡ç†å™¨é…ç½®
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

# ç›‘æŽ§ç›®æ ‡é…ç½®
scrape_configs:
  # Prometheusè‡ªç›‘æŽ§
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Node Exporter - ç³»ç»ŸæŒ‡æ ‡
  - job_name: 'node-exporter'
    static_configs:
      - targets: 
        - 'node-exporter:9100'
    scrape_interval: 10s
    metrics_path: /metrics

  # cAdvisor - å®¹å™¨æŒ‡æ ‡
  - job_name: 'cadvisor'
    static_configs:
      - targets:
        - 'cadvisor:8080'
    scrape_interval: 10s
    metrics_path: /metrics

  # Docker daemon metrics
  - job_name: 'docker'
    static_configs:
      - targets:
        - 'docker-host:9323'
    scrape_interval: 10s

  # åº”ç”¨æŒ‡æ ‡ - æœåŠ¡å‘çŽ°
  - job_name: 'myapp'
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        port: 3000
    relabel_configs:
      - source_labels: [__meta_docker_container_label_com_docker_swarm_service_name]
        regex: myapp-web
        action: keep
      - source_labels: [__meta_docker_container_label_prometheus_scrape]
        regex: true
        action: keep
      - source_labels: [__meta_docker_port_private]
        regex: 3000
        action: keep

  # æ•°æ®åº“ç›‘æŽ§
  - job_name: 'postgres'
    static_configs:
      - targets: ['postgres-exporter:9187']

  # Redisç›‘æŽ§  
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']

  # Nginxç›‘æŽ§
  - job_name: 'nginx'
    static_configs:
      - targets: ['nginx-exporter:9113']

# è¿œç¨‹å†™å…¥é…ç½®ï¼ˆå¯é€‰ï¼‰
remote_write:
  - url: "https://prometheus-remote-write.example.com/api/v1/write"
    basic_auth:
      username: "user"
      password: "password"
```

### 2. å‘Šè­¦è§„åˆ™é…ç½®

```yaml
# alert_rules.yml
groups:
  - name: container_alerts
    rules:
      # å®¹å™¨åœæ­¢è¿è¡Œ
      - alert: ContainerDown
        expr: up{job="cadvisor"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Container is down"
          description: "Container {{ $labels.instance }} has been down for more than 1 minute."

      # å®¹å™¨CPUä½¿ç”¨çŽ‡è¿‡é«˜
      - alert: ContainerHighCPU
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage in container"
          description: "Container {{ $labels.name }} CPU usage is above 80% for 5 minutes."

      # å®¹å™¨å†…å­˜ä½¿ç”¨çŽ‡è¿‡é«˜
      - alert: ContainerHighMemory
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 90
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage in container"
          description: "Container {{ $labels.name }} memory usage is above 90%."

      # å®¹å™¨é‡å¯é¢‘ç¹
      - alert: ContainerRestartTooMuch
        expr: increase(container_start_time_seconds[1h]) > 5
        for: 0m
        labels:
          severity: warning
        annotations:
          summary: "Container restarting too much"
          description: "Container {{ $labels.name }} has restarted more than 5 times in the last hour."

  - name: application_alerts
    rules:
      # HTTPé”™è¯¯çŽ‡è¿‡é«˜
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100 > 5
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate"
          description: "Error rate is above 5% for 5 minutes."

      # å“åº”æ—¶é—´è¿‡é•¿
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency"
          description: "95th percentile latency is above 1 second."

      # æ•°æ®åº“è¿žæŽ¥å¤±è´¥
      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Database is down"
          description: "PostgreSQL database has been down for more than 1 minute."

  - name: system_alerts
    rules:
      # ç³»ç»Ÿè´Ÿè½½è¿‡é«˜
      - alert: HighSystemLoad
        expr: node_load1 > node_machine_info{cores="2"} * 0.8
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High system load"
          description: "System load is above 80% of CPU cores."

      # ç£ç›˜ç©ºé—´ä¸è¶³
      - alert: DiskSpaceLow
        expr: (1 - node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 > 85
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Disk space low"
          description: "Disk space usage is above 85% on {{ $labels.device }}."

      # å†…å­˜ä½¿ç”¨çŽ‡è¿‡é«˜
      - alert: HighMemoryUsage
        expr: (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High memory usage"
          description: "Memory usage is above 90%."
```

### 3. Grafanaä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "id": null,
    "title": "Docker Container Monitoring",
    "tags": ["docker", "containers"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Container CPU Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(container_cpu_usage_seconds_total{name!=\"\"}[5m]) * 100",
            "legendFormat": "{{ name }}"
          }
        ],
        "yAxes": [
          {
            "label": "Percent",
            "max": 100,
            "min": 0
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 0
        }
      },
      {
        "id": 2,
        "title": "Container Memory Usage", 
        "type": "graph",
        "targets": [
          {
            "expr": "container_memory_usage_bytes{name!=\"\"}",
            "legendFormat": "{{ name }}"
          }
        ],
        "yAxes": [
          {
            "label": "Bytes"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 0
        }
      },
      {
        "id": 3,
        "title": "HTTP Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{ method }} {{ status }}"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 0,
          "y": 8
        }
      },
      {
        "id": 4,
        "title": "HTTP Response Time",
        "type": "graph", 
        "targets": [
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "50th percentile"
          },
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.99, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "99th percentile"
          }
        ],
        "gridPos": {
          "h": 8,
          "w": 12,
          "x": 12,
          "y": 8
        }
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "30s"
  }
}
```

## ðŸ“ æ—¥å¿—ç®¡ç†ç³»ç»Ÿ

### 1. ELK Stacké…ç½®

```yaml
# elk-stack.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G
    networks:
      - logging

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    volumes:
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/config:/usr/share/logstash/config:ro
    ports:
      - "5044:5044"
      - "5000:5000"
    environment:
      - "LS_JAVA_OPTS=-Xms512m -Xmx512m"
    depends_on:
      - elasticsearch
    networks:
      - logging

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - logging

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.5.0
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: filebeat -e -strict.perms=false
    depends_on:
      - logstash
    deploy:
      mode: global
    networks:
      - logging

volumes:
  elasticsearch_data:

networks:
  logging:
    external: true
```

### 2. Logstashé…ç½®

```ruby
# logstash/pipeline/logstash.conf
input {
  beats {
    port => 5044
  }
  
  # ç›´æŽ¥ä»ŽDocker APIæ”¶é›†æ—¥å¿—
  http {
    port => 5000
    codec => json
  }
}

filter {
  # å¤„ç†æ¥è‡ªFilebeatçš„Dockeræ—¥å¿—
  if [fields][log_type] == "docker" {
    # è§£æžDockeræ—¥å¿—å…ƒæ•°æ®
    json {
      source => "message"
      target => "docker"
    }
    
    # æå–å®¹å™¨ä¿¡æ¯
    if [container][name] {
      mutate {
        add_field => { "container_name" => "%{[container][name]}" }
      }
    }
    
    # è§£æžæ—¶é—´æˆ³
    date {
      match => [ "[docker][time]", "ISO8601" ]
      target => "@timestamp"
    }
    
    # åº”ç”¨æ—¥å¿—è§£æž
    if [container_name] =~ /myapp/ {
      # è§£æžåº”ç”¨JSONæ—¥å¿—
      if [docker][log] =~ /^\{/ {
        json {
          source => "[docker][log]"
          target => "app"
        }
        
        # æå–æ—¥å¿—çº§åˆ«
        if [app][level] {
          mutate {
            add_field => { "log_level" => "%{[app][level]}" }
          }
        }
        
        # æå–è¯·æ±‚ID
        if [app][request_id] {
          mutate {
            add_field => { "request_id" => "%{[app][request_id]}" }
          }
        }
      }
    }
    
    # Nginxæ—¥å¿—è§£æž
    if [container_name] =~ /nginx/ {
      grok {
        match => { "[docker][log]" => "%{COMBINEDAPACHELOG}" }
      }
      
      # è§£æžå“åº”æ—¶é—´
      if [response] {
        mutate {
          convert => { "response" => "integer" }
        }
      }
    }
  }
  
  # æ·»åŠ çŽ¯å¢ƒæ ‡ç­¾
  mutate {
    add_field => { "environment" => "production" }
    add_field => { "cluster" => "docker-swarm" }
  }
  
  # ç§»é™¤ä¸éœ€è¦çš„å­—æ®µ
  mutate {
    remove_field => [ "agent", "ecs", "host", "input" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "docker-logs-%{+YYYY.MM.dd}"
  }
  
  # è¾“å‡ºé”™è¯¯æ—¥å¿—åˆ°ä¸“é—¨çš„ç´¢å¼•
  if [log_level] == "error" or [response] >= 400 {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "docker-errors-%{+YYYY.MM.dd}"
    }
  }
  
  # è°ƒè¯•è¾“å‡º
  stdout { 
    codec => rubydebug 
  }
}
```

### 3. Filebeaté…ç½®

```yaml
# filebeat/filebeat.yml
filebeat.inputs:
  # Dockerå®¹å™¨æ—¥å¿—
  - type: container
    paths:
      - /var/lib/docker/containers/*/*.log
    processors:
      - add_docker_metadata:
          host: "unix:///var/run/docker.sock"
      - decode_json_fields:
          fields: ["message"]
          target: ""
          overwrite_keys: true
    fields:
      log_type: docker
    fields_under_root: true

  # ç³»ç»Ÿæ—¥å¿—
  - type: log
    paths:
      - /var/log/syslog
      - /var/log/auth.log
    fields:
      log_type: system
    fields_under_root: true

# å¤„ç†å™¨é…ç½®
processors:
  - add_host_metadata:
      when.not.contains.tags: forwarded
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~

# è¾“å‡ºé…ç½®
output.logstash:
  hosts: ["logstash:5044"]

# æ—¥å¿—çº§åˆ«
logging.level: info
logging.to_files: true
logging.files:
  path: /var/log/filebeat
  name: filebeat
  keepfiles: 7
  permissions: 0644
```

## ðŸš¨ å‘Šè­¦ç®¡ç†ç³»ç»Ÿ

### 1. Alertmanageré…ç½®

```yaml
# alertmanager.yml
global:
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'app_password'

# è·¯ç”±é…ç½®
route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
    # ä¸¥é‡å‘Šè­¦
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 10s
      repeat_interval: 5m
    
    # åº”ç”¨å‘Šè­¦
    - match:
        service: myapp
      receiver: 'app-team'
    
    # åŸºç¡€è®¾æ–½å‘Šè­¦
    - match_re:
        alertname: ^(ContainerDown|HighSystemLoad|DiskSpaceLow)$
      receiver: 'infrastructure-team'

# æŽ¥æ”¶å™¨é…ç½®
receivers:
  # é»˜è®¤æŽ¥æ”¶å™¨
  - name: 'default'
    email_configs:
      - to: 'devops@example.com'
        subject: '[ALERT] {{ .GroupLabels.alertname }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Severity: {{ .Labels.severity }}
          {{ end }}

  # ä¸¥é‡å‘Šè­¦æŽ¥æ”¶å™¨
  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@example.com'
        subject: '[CRITICAL] {{ .GroupLabels.alertname }}'
        body: |
          CRITICAL ALERT!
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt }}
          {{ end }}
    
    # Slacké€šçŸ¥
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
        channel: '#alerts'
        title: 'Critical Alert: {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Instance:* {{ .Labels.instance }}
          *Severity:* {{ .Labels.severity }}
          {{ end }}
    
    # ä¼ä¸šå¾®ä¿¡é€šçŸ¥
    wechat_configs:
      - api_url: 'https://qyapi.weixin.qq.com/cgi-bin/webhook/send'
        corp_id: 'your_corp_id'
        api_secret: 'your_api_secret'
        to_user: '@all'
        message: |
          ä¸¥é‡å‘Šè­¦é€šçŸ¥
          {{ range .Alerts }}
          å‘Šè­¦: {{ .Annotations.summary }}
          æè¿°: {{ .Annotations.description }}
          å®žä¾‹: {{ .Labels.instance }}
          {{ end }}

  # åº”ç”¨å›¢é˜ŸæŽ¥æ”¶å™¨
  - name: 'app-team'
    email_configs:
      - to: 'app-team@example.com'
        subject: '[APP] {{ .GroupLabels.alertname }}'

  # åŸºç¡€è®¾æ–½å›¢é˜ŸæŽ¥æ”¶å™¨
  - name: 'infrastructure-team'
    email_configs:
      - to: 'infra-team@example.com'
        subject: '[INFRA] {{ .GroupLabels.alertname }}'

# æŠ‘åˆ¶è§„åˆ™
inhibit_rules:
  # å¦‚æžœå®žä¾‹å®•æœºï¼ŒæŠ‘åˆ¶è¯¥å®žä¾‹çš„å…¶ä»–å‘Šè­¦
  - source_match:
      alertname: 'InstanceDown'
    target_match_re:
      instance: '.*'
    equal: ['instance']
  
  # å¦‚æžœæœ‰ä¸¥é‡å‘Šè­¦ï¼ŒæŠ‘åˆ¶åŒä¸€æœåŠ¡çš„è­¦å‘Šå‘Šè­¦
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['service']
```

### 2. è‡ªå®šä¹‰å‘Šè­¦è„šæœ¬

```bash
#!/bin/bash
# alert-webhook.sh - Webhookå‘Šè­¦å¤„ç†è„šæœ¬

# æŽ¥æ”¶Alertmanagerçš„webhookæ•°æ®
read -r ALERT_DATA

# è§£æžå‘Šè­¦æ•°æ®
ALERT_NAME=$(echo "$ALERT_DATA" | jq -r '.alerts[0].labels.alertname')
SEVERITY=$(echo "$ALERT_DATA" | jq -r '.alerts[0].labels.severity')
INSTANCE=$(echo "$ALERT_DATA" | jq -r '.alerts[0].labels.instance')
DESCRIPTION=$(echo "$ALERT_DATA" | jq -r '.alerts[0].annotations.description')
STATUS=$(echo "$ALERT_DATA" | jq -r '.status')

echo "æ”¶åˆ°å‘Šè­¦: $ALERT_NAME ($SEVERITY) - $INSTANCE"

# æ ¹æ®å‘Šè­¦ç±»åž‹æ‰§è¡Œç›¸åº”åŠ¨ä½œ
case $ALERT_NAME in
    "ContainerDown")
        echo "å®¹å™¨ä¸‹çº¿å‘Šè­¦ï¼Œå°è¯•é‡å¯..."
        # è‡ªåŠ¨é‡å¯å®¹å™¨
        CONTAINER_NAME=$(echo "$INSTANCE" | cut -d: -f1)
        docker service update --force $CONTAINER_NAME
        ;;
        
    "HighMemoryUsage")
        echo "å†…å­˜ä½¿ç”¨çŽ‡è¿‡é«˜ï¼Œæ”¶é›†è¯Šæ–­ä¿¡æ¯..."
        # æ”¶é›†ç³»ç»Ÿä¿¡æ¯
        docker stats --no-stream > /tmp/container-stats-$(date +%Y%m%d-%H%M%S).log
        ;;
        
    "DiskSpaceLow")
        echo "ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶..."
        # æ¸…ç†Dockerç³»ç»Ÿ
        docker system prune -f
        ;;
        
    *)
        echo "æœªçŸ¥å‘Šè­¦ç±»åž‹: $ALERT_NAME"
        ;;
esac

# è®°å½•å‘Šè­¦åˆ°æ—¥å¿—
echo "$(date): $STATUS - $ALERT_NAME - $DESCRIPTION" >> /var/log/alerts.log

# å‘é€åˆ°è‡ªå®šä¹‰é€šçŸ¥ç³»ç»Ÿ
curl -X POST "http://notification-service/webhook" \
    -H "Content-Type: application/json" \
    -d "{
        \"alert\": \"$ALERT_NAME\",
        \"severity\": \"$SEVERITY\",
        \"instance\": \"$INSTANCE\",
        \"description\": \"$DESCRIPTION\",
        \"status\": \"$STATUS\",
        \"timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"
    }"
```

## ðŸ“Š åº”ç”¨æ€§èƒ½ç›‘æŽ§(APM)

### 1. åº”ç”¨æŒ‡æ ‡æ”¶é›†

```javascript
// metrics.js - Node.jsåº”ç”¨æŒ‡æ ‡æ”¶é›†
const promClient = require('prom-client');
const express = require('express');

// åˆ›å»ºæŒ‡æ ‡æ³¨å†Œè¡¨
const register = new promClient.Registry();

// ç³»ç»ŸæŒ‡æ ‡
promClient.collectDefaultMetrics({ register });

// HTTPè¯·æ±‚æŒ‡æ ‡
const httpRequestsTotal = new promClient.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status_code'],
  registers: [register]
});

const httpRequestDuration = new promClient.Histogram({
  name: 'http_request_duration_seconds',
  help: 'HTTP request duration in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10],
  registers: [register]
});

// ä¸šåŠ¡æŒ‡æ ‡
const userRegistrations = new promClient.Counter({
  name: 'user_registrations_total',
  help: 'Total number of user registrations',
  registers: [register]
});

const activeUsers = new promClient.Gauge({
  name: 'active_users',
  help: 'Number of currently active users',
  registers: [register]
});

const orderValue = new promClient.Summary({
  name: 'order_value_dollars',
  help: 'Order value in dollars',
  percentiles: [0.5, 0.9, 0.95, 0.99],
  registers: [register]
});

// æ•°æ®åº“è¿žæŽ¥æ± æŒ‡æ ‡
const dbConnectionsActive = new promClient.Gauge({
  name: 'database_connections_active',
  help: 'Number of active database connections',
  registers: [register]
});

const dbQueryDuration = new promClient.Histogram({
  name: 'database_query_duration_seconds',
  help: 'Database query duration',
  labelNames: ['query_type', 'table'],
  buckets: [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5],
  registers: [register]
});

// ä¸­é—´ä»¶ï¼šè®°å½•HTTPæŒ‡æ ‡
const metricsMiddleware = (req, res, next) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000;
    const route = req.route ? req.route.path : req.path;
    
    httpRequestsTotal.inc({
      method: req.method,
      route: route,
      status_code: res.statusCode
    });
    
    httpRequestDuration.observe({
      method: req.method,
      route: route,
      status_code: res.statusCode
    }, duration);
  });
  
  next();
};

// æ•°æ®åº“æŸ¥è¯¢åŒ…è£…å™¨
const instrumentedQuery = async (query, params, queryType, table) => {
  const start = Date.now();
  
  try {
    const result = await db.query(query, params);
    const duration = (Date.now() - start) / 1000;
    
    dbQueryDuration.observe({
      query_type: queryType,
      table: table
    }, duration);
    
    return result;
  } catch (error) {
    dbQueryDuration.observe({
      query_type: queryType,
      table: table
    }, (Date.now() - start) / 1000);
    throw error;
  }
};

// æš´éœ²æŒ‡æ ‡ç«¯ç‚¹
const app = express();
app.use(metricsMiddleware);

app.get('/metrics', async (req, res) => {
  try {
    // æ›´æ–°åŠ¨æ€æŒ‡æ ‡
    updateDynamicMetrics();
    
    res.set('Content-Type', register.contentType);
    res.end(await register.metrics());
  } catch (error) {
    res.status(500).end(error);
  }
});

// æ›´æ–°åŠ¨æ€æŒ‡æ ‡
function updateDynamicMetrics() {
  // æ›´æ–°æ´»è·ƒç”¨æˆ·æ•°
  const activeUserCount = getActiveUserCount();
  activeUsers.set(activeUserCount);
  
  // æ›´æ–°æ•°æ®åº“è¿žæŽ¥æ•°
  const dbConnections = getDbConnectionCount();
  dbConnectionsActive.set(dbConnections);
}

module.exports = {
  register,
  httpRequestsTotal,
  httpRequestDuration,
  userRegistrations,
  activeUsers,
  orderValue,
  instrumentedQuery,
  metricsMiddleware
};
```

### 2. åˆ†å¸ƒå¼é“¾è·¯è¿½è¸ª

```javascript
// tracing.js - åˆ†å¸ƒå¼é“¾è·¯è¿½è¸ª
const { NodeSDK } = require('@opentelemetry/sdk-node');
const { Resource } = require('@opentelemetry/resources');
const { SemanticResourceAttributes } = require('@opentelemetry/semantic-conventions');
const { JaegerExporter } = require('@opentelemetry/exporter-jaeger');
const { getNodeAutoInstrumentations } = require('@opentelemetry/auto-instrumentations-node');

// é…ç½®èµ„æºä¿¡æ¯
const resource = new Resource({
  [SemanticResourceAttributes.SERVICE_NAME]: 'myapp',
  [SemanticResourceAttributes.SERVICE_VERSION]: process.env.APP_VERSION || '1.0.0',
  [SemanticResourceAttributes.DEPLOYMENT_ENVIRONMENT]: process.env.NODE_ENV || 'development',
});

// é…ç½®Jaegerå¯¼å‡ºå™¨
const jaegerExporter = new JaegerExporter({
  endpoint: process.env.JAEGER_ENDPOINT || 'http://jaeger:14268/api/traces',
});

// åˆå§‹åŒ–SDK
const sdk = new NodeSDK({
  resource: resource,
  traceExporter: jaegerExporter,
  instrumentations: [
    getNodeAutoInstrumentations({
      // ç¦ç”¨æŸäº›è‡ªåŠ¨åŒ–instrument
      '@opentelemetry/instrumentation-fs': {
        enabled: false,
      },
    }),
  ],
});

// å¯åŠ¨è¿½è¸ª
sdk.start();

// æ‰‹åŠ¨åˆ›å»ºspançš„å·¥å…·å‡½æ•°
const opentelemetry = require('@opentelemetry/api');

function createSpan(name, fn) {
  const tracer = opentelemetry.trace.getTracer('myapp');
  
  return tracer.startActiveSpan(name, async (span) => {
    try {
      const result = await fn(span);
      span.setStatus({ code: opentelemetry.SpanStatusCode.OK });
      return result;
    } catch (error) {
      span.recordException(error);
      span.setStatus({
        code: opentelemetry.SpanStatusCode.ERROR,
        message: error.message,
      });
      throw error;
    } finally {
      span.end();
    }
  });
}

module.exports = {
  createSpan,
  tracer: opentelemetry.trace.getTracer('myapp')
};
```

## ðŸ”§ ç›‘æŽ§è‡ªåŠ¨åŒ–è„šæœ¬

### 1. å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# health-check-monitor.sh

SERVICES=("myapp-web" "myapp-db" "myapp-cache")
SLACK_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
CHECK_INTERVAL=60

echo "ðŸ¥ å¯åŠ¨å¥åº·æ£€æŸ¥ç›‘æŽ§..."

while true; do
    echo "$(date): æ‰§è¡Œå¥åº·æ£€æŸ¥..."
    
    for service in "${SERVICES[@]}"; do
        echo "æ£€æŸ¥æœåŠ¡: $service"
        
        # æ£€æŸ¥æœåŠ¡çŠ¶æ€
        service_status=$(docker service ps $service --format "{{.CurrentState}}" --filter "desired-state=running" | head -1)
        
        if [[ $service_status =~ ^Running ]]; then
            echo "âœ… $service è¿è¡Œæ­£å¸¸"
            
            # é¢å¤–çš„å¥åº·æ£€æŸ¥
            if [[ $service == "myapp-web" ]]; then
                # HTTPå¥åº·æ£€æŸ¥
                if ! curl -f -s --max-time 10 http://localhost:3000/health >/dev/null; then
                    send_alert "âš ï¸ $service HTTPå¥åº·æ£€æŸ¥å¤±è´¥"
                fi
            elif [[ $service == "myapp-db" ]]; then
                # æ•°æ®åº“è¿žæŽ¥æ£€æŸ¥
                if ! docker exec $(docker ps -q -f name=$service) pg_isready -U app >/dev/null 2>&1; then
                    send_alert "âš ï¸ $service æ•°æ®åº“è¿žæŽ¥æ£€æŸ¥å¤±è´¥"
                fi
            fi
            
        else
            send_alert "âŒ $service çŠ¶æ€å¼‚å¸¸: $service_status"
        fi
    done
    
    sleep $CHECK_INTERVAL
done

send_alert() {
    local message="$1"
    echo "$message"
    
    # å‘é€åˆ°Slack
    if [ ! -z "$SLACK_WEBHOOK_URL" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"$message\"}" \
            $SLACK_WEBHOOK_URL
    fi
    
    # è®°å½•åˆ°ç³»ç»Ÿæ—¥å¿—
    logger "$message"
}
```

### 2. æ€§èƒ½ç›‘æŽ§è„šæœ¬

```bash
#!/bin/bash
# performance-monitor.sh

THRESHOLD_CPU=80
THRESHOLD_MEMORY=85
THRESHOLD_DISK=90
REPORT_INTERVAL=300  # 5åˆ†é’Ÿ

echo "ðŸ“Š å¯åŠ¨æ€§èƒ½ç›‘æŽ§..."

while true; do
    echo "$(date): æ”¶é›†æ€§èƒ½æŒ‡æ ‡..."
    
    # CPUä½¿ç”¨çŽ‡
    cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1 | tr -d ' us,')
    cpu_usage=${cpu_usage%.*}  # å–æ•´æ•°éƒ¨åˆ†
    
    if [ "$cpu_usage" -gt "$THRESHOLD_CPU" ]; then
        echo "âš ï¸ CPUä½¿ç”¨çŽ‡è¿‡é«˜: ${cpu_usage}%"
        
        # æ‰¾å‡ºCPUä½¿ç”¨çŽ‡æœ€é«˜çš„å®¹å™¨
        echo "CPUä½¿ç”¨çŽ‡æœ€é«˜çš„å®¹å™¨:"
        docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}" | sort -k2 -rn | head -5
    fi
    
    # å†…å­˜ä½¿ç”¨çŽ‡
    memory_info=$(free | grep Mem)
    total_memory=$(echo $memory_info | awk '{print $2}')
    used_memory=$(echo $memory_info | awk '{print $3}')
    memory_usage=$(( used_memory * 100 / total_memory ))
    
    if [ "$memory_usage" -gt "$THRESHOLD_MEMORY" ]; then
        echo "âš ï¸ å†…å­˜ä½¿ç”¨çŽ‡è¿‡é«˜: ${memory_usage}%"
        
        # æ‰¾å‡ºå†…å­˜ä½¿ç”¨æœ€é«˜çš„å®¹å™¨
        echo "å†…å­˜ä½¿ç”¨æœ€é«˜çš„å®¹å™¨:"
        docker stats --no-stream --format "table {{.Container}}\t{{.MemUsage}}" | sort -k2 -rn | head -5
    fi
    
    # ç£ç›˜ä½¿ç”¨çŽ‡
    while read output; do
        usage=$(echo $output | awk '{print $5}' | cut -d'%' -f1)
        partition=$(echo $output | awk '{print $6}')
        
        if [ "$usage" -gt "$THRESHOLD_DISK" ]; then
            echo "âš ï¸ ç£ç›˜ä½¿ç”¨çŽ‡è¿‡é«˜: $partition ${usage}%"
            
            # æ‰¾å‡ºå¤§æ–‡ä»¶
            echo "æœ€å¤§çš„æ–‡ä»¶:"
            find $partition -type f -size +100M -exec ls -lh {} \; 2>/dev/null | sort -k5 -rh | head -5
        fi
    done < <(df -h | grep -vE '^Filesystem|tmpfs|cdrom')
    
    # Dockerç³»ç»Ÿä¿¡æ¯
    echo ""
    echo "ðŸ³ Dockerç³»ç»Ÿä¿¡æ¯:"
    docker system df
    
    # å®¹å™¨èµ„æºä½¿ç”¨TOP 5
    echo ""
    echo "ðŸ“‹ èµ„æºä½¿ç”¨TOP 5:"
    docker stats --no-stream --format "table {{.Container}}\t{{.CPUPerc}}\t{{.MemUsage}}" | sort -k2 -rn | head -6
    
    sleep $REPORT_INTERVAL
done
```

## ðŸ“ ä¸‹ä¸€æ­¥

æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº†Dockerå­¦ä¹ çš„å…¨éƒ¨12ä¸ªç« èŠ‚ã€‚çŽ°åœ¨æ‚¨å¯ä»¥ï¼š

1. **å®žè·µé¡¹ç›®** - ä½¿ç”¨å­¦åˆ°çš„çŸ¥è¯†æž„å»ºå®Œæ•´çš„å®¹å™¨åŒ–åº”ç”¨
2. **æ·±å…¥å­¦ä¹ ** - æŽ¢ç´¢Kubernetesã€æœåŠ¡ç½‘æ ¼ç­‰é«˜çº§å®¹å™¨æŠ€æœ¯
3. **è®¤è¯è€ƒè¯•** - è€ƒè™‘å‚åŠ Dockerè®¤è¯è€ƒè¯•éªŒè¯æ‚¨çš„æŠ€èƒ½

## ðŸŽ¯ æœ¬ç« è¦ç‚¹

- âœ… ç†è§£Dockerç›‘æŽ§ä½“ç³»å’Œæ—¥å¿—ç®¡ç†æž¶æž„
- âœ… æŽŒæ¡Prometheusã€Grafanaç›‘æŽ§å·¥å…·çš„ä½¿ç”¨
- âœ… å­¦ä¼šELK Stackæ—¥å¿—æ”¶é›†å’Œåˆ†æžç³»ç»Ÿ
- âœ… äº†è§£å‘Šè­¦æœºåˆ¶å’Œè‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬
- âœ… æŽŒæ¡åº”ç”¨æ€§èƒ½ç›‘æŽ§å’Œåˆ†å¸ƒå¼è¿½è¸ª

ðŸŽ‰ **æ­å–œæ‚¨å®Œæˆäº†å®Œæ•´çš„Dockerå­¦ä¹ ä¹‹æ—…ï¼**

æ‚¨çŽ°åœ¨å·²ç»å…·å¤‡äº†åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­éƒ¨ç½²ã€ç®¡ç†å’Œç›‘æŽ§Dockeråº”ç”¨çš„å…¨é¢æŠ€èƒ½ã€‚ç»§ç»­å®žè·µå’ŒæŽ¢ç´¢ï¼Œæˆä¸ºå®¹å™¨åŒ–æŠ€æœ¯ä¸“å®¶ï¼ðŸ³
