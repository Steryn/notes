# æ—¥å¿—ç®¡ç†

## ğŸ“‹ æ¦‚è¿°

æ—¥å¿—ç®¡ç†æ˜¯ç°ä»£åº”ç”¨è¿ç»´çš„é‡è¦ç»„æˆéƒ¨åˆ†ï¼ŒåŒ…æ‹¬æ—¥å¿—æ”¶é›†ã€å­˜å‚¨ã€åˆ†æå’Œç›‘æ§ã€‚æœ‰æ•ˆçš„æ—¥å¿—ç®¡ç†èƒ½å¤Ÿå¸®åŠ©å¿«é€Ÿå®šä½é—®é¢˜ã€åˆ†ææ€§èƒ½å’Œç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- ç†è§£æ—¥å¿—ç®¡ç†çš„æ ¸å¿ƒæ¦‚å¿µå’Œé‡è¦æ€§
- æŒæ¡Node.jsåº”ç”¨çš„æ—¥å¿—è®°å½•æœ€ä½³å®è·µ
- å­¦ä¼šé…ç½®é›†ä¸­åŒ–æ—¥å¿—æ”¶é›†ç³»ç»Ÿ
- äº†è§£æ—¥å¿—åˆ†æå’Œå¯è§†åŒ–å·¥å…·

## ğŸ“š æ—¥å¿—ç®¡ç†åŸºç¡€

### æ—¥å¿—çº§åˆ«

```javascript
const LOG_LEVELS = {
  ERROR: 0,    // é”™è¯¯ä¿¡æ¯
  WARN: 1,     // è­¦å‘Šä¿¡æ¯
  INFO: 2,     // ä¸€èˆ¬ä¿¡æ¯
  HTTP: 3,     // HTTPè¯·æ±‚æ—¥å¿—
  VERBOSE: 4,  // è¯¦ç»†ä¿¡æ¯
  DEBUG: 5,    // è°ƒè¯•ä¿¡æ¯
  SILLY: 6     // æœ€è¯¦ç»†ä¿¡æ¯
};
```

### æ—¥å¿—æ ¼å¼æ ‡å‡†

```javascript
// ç»“æ„åŒ–æ—¥å¿—æ ¼å¼
const logEntry = {
  timestamp: '2023-12-07T10:30:00.000Z',
  level: 'info',
  message: 'User login successful',
  service: 'auth-service',
  version: '1.2.0',
  traceId: 'abc123-def456-ghi789',
  userId: 'user_12345',
  ip: '192.168.1.100',
  userAgent: 'Mozilla/5.0...',
  duration: 150,
  statusCode: 200,
  method: 'POST',
  url: '/api/auth/login',
  metadata: {
    sessionId: 'sess_789xyz',
    feature: 'authentication'
  }
};
```

## ğŸ›  Node.jsæ—¥å¿—å®ç°

### Winstonæ—¥å¿—åº“é…ç½®

```javascript
// logger.js
const winston = require('winston');
const path = require('path');

// è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼
const logFormat = winston.format.combine(
  winston.format.timestamp({
    format: 'YYYY-MM-DD HH:mm:ss.SSS'
  }),
  winston.format.errors({ stack: true }),
  winston.format.json(),
  winston.format.printf(({ timestamp, level, message, service, traceId, ...meta }) => {
    const logEntry = {
      timestamp,
      level: level.toUpperCase(),
      service: service || 'nodejs-app',
      message,
      traceId,
      ...meta
    };
    return JSON.stringify(logEntry);
  })
);

// åˆ›å»ºloggerå®ä¾‹
const logger = winston.createLogger({
  level: process.env.LOG_LEVEL || 'info',
  format: logFormat,
  defaultMeta: {
    service: process.env.SERVICE_NAME || 'nodejs-app',
    version: process.env.APP_VERSION || '1.0.0',
    hostname: require('os').hostname(),
    pid: process.pid
  },
  transports: [
    // æ§åˆ¶å°è¾“å‡º
    new winston.transports.Console({
      format: process.env.NODE_ENV === 'development' 
        ? winston.format.combine(
            winston.format.colorize(),
            winston.format.simple()
          )
        : logFormat
    }),
    
    // æ–‡ä»¶è¾“å‡º - æ‰€æœ‰æ—¥å¿—
    new winston.transports.File({
      filename: path.join(process.env.LOG_DIR || './logs', 'app.log'),
      maxsize: 10485760, // 10MB
      maxFiles: 5,
      tailable: true
    }),
    
    // æ–‡ä»¶è¾“å‡º - é”™è¯¯æ—¥å¿—
    new winston.transports.File({
      filename: path.join(process.env.LOG_DIR || './logs', 'error.log'),
      level: 'error',
      maxsize: 10485760, // 10MB
      maxFiles: 5,
      tailable: true
    }),
    
    // HTTPä¼ è¾“ - å‘é€åˆ°æ—¥å¿—æ”¶é›†ç³»ç»Ÿ
    new winston.transports.Http({
      host: process.env.LOG_SERVER_HOST,
      port: process.env.LOG_SERVER_PORT,
      path: '/logs',
      ssl: process.env.LOG_SERVER_SSL === 'true'
    })
  ],
  
  // å¼‚å¸¸å¤„ç†
  exceptionHandlers: [
    new winston.transports.File({
      filename: path.join(process.env.LOG_DIR || './logs', 'exceptions.log'),
      maxsize: 10485760,
      maxFiles: 3
    })
  ],
  
  // æ‹’ç»å¤„ç†
  rejectionHandlers: [
    new winston.transports.File({
      filename: path.join(process.env.LOG_DIR || './logs', 'rejections.log'),
      maxsize: 10485760,
      maxFiles: 3
    })
  ]
});

// ç”Ÿäº§ç¯å¢ƒä¸è¾“å‡ºåˆ°æ§åˆ¶å°
if (process.env.NODE_ENV === 'production') {
  logger.remove(winston.transports.Console);
}

module.exports = logger;
```

### è¯·æ±‚æ—¥å¿—ä¸­é—´ä»¶

```javascript
// middleware/request-logger.js
const logger = require('../logger');
const { v4: uuidv4 } = require('uuid');

function requestLogger() {
  return (req, res, next) => {
    const startTime = Date.now();
    const traceId = uuidv4();
    
    // æ·»åŠ traceIdåˆ°è¯·æ±‚å¯¹è±¡
    req.traceId = traceId;
    
    // è®°å½•è¯·æ±‚å¼€å§‹
    logger.info('Request started', {
      traceId,
      method: req.method,
      url: req.url,
      userAgent: req.get('User-Agent'),
      ip: req.ip || req.connection.remoteAddress,
      headers: filterSensitiveHeaders(req.headers),
      query: req.query,
      body: filterSensitiveData(req.body)
    });
    
    // ç›‘å¬å“åº”ç»“æŸ
    res.on('finish', () => {
      const duration = Date.now() - startTime;
      const logLevel = res.statusCode >= 400 ? 'error' : 'info';
      
      logger.log(logLevel, 'Request completed', {
        traceId,
        method: req.method,
        url: req.url,
        statusCode: res.statusCode,
        duration,
        contentLength: res.get('Content-Length') || 0,
        userAgent: req.get('User-Agent'),
        ip: req.ip || req.connection.remoteAddress
      });
    });
    
    next();
  };
}

function filterSensitiveHeaders(headers) {
  const filtered = { ...headers };
  const sensitiveHeaders = ['authorization', 'cookie', 'x-api-key'];
  
  sensitiveHeaders.forEach(header => {
    if (filtered[header]) {
      filtered[header] = '[REDACTED]';
    }
  });
  
  return filtered;
}

function filterSensitiveData(data) {
  if (!data || typeof data !== 'object') return data;
  
  const filtered = { ...data };
  const sensitiveFields = ['password', 'token', 'secret', 'key'];
  
  Object.keys(filtered).forEach(key => {
    if (sensitiveFields.some(field => key.toLowerCase().includes(field))) {
      filtered[key] = '[REDACTED]';
    }
  });
  
  return filtered;
}

module.exports = requestLogger;
```

### é”™è¯¯æ—¥å¿—å¤„ç†

```javascript
// middleware/error-logger.js
const logger = require('../logger');

function errorLogger() {
  return (err, req, res, next) => {
    // è®°å½•é”™è¯¯è¯¦æƒ…
    logger.error('Application error', {
      traceId: req.traceId,
      error: {
        name: err.name,
        message: err.message,
        stack: err.stack,
        code: err.code
      },
      request: {
        method: req.method,
        url: req.url,
        headers: req.headers,
        body: req.body,
        params: req.params,
        query: req.query
      },
      user: {
        id: req.user?.id,
        email: req.user?.email
      },
      session: {
        id: req.sessionID
      }
    });
    
    // ç»§ç»­é”™è¯¯å¤„ç†æµç¨‹
    next(err);
  };
}

module.exports = errorLogger;
```

### ä¸šåŠ¡æ—¥å¿—è®°å½•

```javascript
// services/user-service.js
const logger = require('../logger');

class UserService {
  async createUser(userData, traceId) {
    try {
      logger.info('Creating new user', {
        traceId,
        operation: 'user_creation',
        email: userData.email,
        role: userData.role
      });
      
      // ç”¨æˆ·åˆ›å»ºé€»è¾‘
      const user = await User.create(userData);
      
      logger.info('User created successfully', {
        traceId,
        operation: 'user_creation',
        userId: user.id,
        email: user.email,
        duration: Date.now() - startTime
      });
      
      return user;
    } catch (error) {
      logger.error('Failed to create user', {
        traceId,
        operation: 'user_creation',
        error: {
          name: error.name,
          message: error.message,
          code: error.code
        },
        userData: {
          email: userData.email,
          role: userData.role
        }
      });
      
      throw error;
    }
  }
  
  async loginUser(email, password, traceId) {
    const startTime = Date.now();
    
    try {
      logger.info('User login attempt', {
        traceId,
        operation: 'user_login',
        email
      });
      
      const user = await User.findByEmail(email);
      if (!user) {
        logger.warn('Login failed - user not found', {
          traceId,
          operation: 'user_login',
          email,
          reason: 'user_not_found'
        });
        throw new Error('Invalid credentials');
      }
      
      const isValid = await bcrypt.compare(password, user.password);
      if (!isValid) {
        logger.warn('Login failed - invalid password', {
          traceId,
          operation: 'user_login',
          userId: user.id,
          email,
          reason: 'invalid_password'
        });
        throw new Error('Invalid credentials');
      }
      
      logger.info('User login successful', {
        traceId,
        operation: 'user_login',
        userId: user.id,
        email,
        duration: Date.now() - startTime
      });
      
      return user;
    } catch (error) {
      logger.error('Login error', {
        traceId,
        operation: 'user_login',
        email,
        error: {
          name: error.name,
          message: error.message
        },
        duration: Date.now() - startTime
      });
      
      throw error;
    }
  }
}

module.exports = UserService;
```

## ğŸ“Š æ—¥å¿—æ”¶é›†ç³»ç»Ÿ

### ELK Stacké…ç½®

#### Elasticsearché…ç½®

```yaml
# docker-compose.yml - Elasticsearch
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - cluster.name=nodejs-logs
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
    ulimits:
      memlock:
        soft: -1
        hard: -1
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    networks:
      - elk-network

  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.0
    container_name: logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    ports:
      - "5044:5044"
      - "5000:5000/tcp"
      - "5000:5000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: "-Xmx512m -Xms512m"
    networks:
      - elk-network
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:8.10.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_URL: http://elasticsearch:9200
      ELASTICSEARCH_HOSTS: '["http://elasticsearch:9200"]'
    networks:
      - elk-network
    depends_on:
      - elasticsearch

volumes:
  elasticsearch_data:

networks:
  elk-network:
    driver: bridge
```

#### Logstashé…ç½®

```ruby
# logstash/pipeline/nodejs-logs.conf
input {
  # ä»æ–‡ä»¶è¯»å–æ—¥å¿—
  file {
    path => "/var/log/nodejs/*.log"
    start_position => "beginning"
    codec => "json"
    tags => ["nodejs", "file"]
  }
  
  # ä»HTTPæ¥æ”¶æ—¥å¿—
  http {
    port => 5000
    codec => "json"
    tags => ["nodejs", "http"]
  }
  
  # ä»Beatsæ¥æ”¶æ—¥å¿—
  beats {
    port => 5044
    tags => ["nodejs", "beats"]
  }
}

filter {
  # è§£ææ—¶é—´æˆ³
  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    target => "@timestamp"
  }
  
  # è§£ææ—¥å¿—çº§åˆ«
  if [level] {
    mutate {
      uppercase => [ "level" ]
    }
  }
  
  # è§£æHTTPè¯·æ±‚æ—¥å¿—
  if [method] and [url] {
    mutate {
      add_field => { "log_type" => "http_request" }
    }
    
    # æå–URLè·¯å¾„
    grok {
      match => { "url" => "(?<path>[^?]+)" }
    }
  }
  
  # è§£æé”™è¯¯æ—¥å¿—
  if [level] == "ERROR" {
    mutate {
      add_field => { "log_type" => "error" }
    }
  }
  
  # åœ°ç†ä½ç½®è§£æï¼ˆå¦‚æœæœ‰IPï¼‰
  if [ip] {
    geoip {
      source => "ip"
      target => "geoip"
    }
  }
  
  # ç”¨æˆ·ä»£ç†è§£æ
  if [userAgent] {
    useragent {
      source => "userAgent"
      target => "ua"
    }
  }
  
  # æ·»åŠ ç¯å¢ƒæ ‡è¯†
  mutate {
    add_field => { "environment" => "${ENVIRONMENT:unknown}" }
  }
}

output {
  # è¾“å‡ºåˆ°Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "nodejs-logs-%{+YYYY.MM.dd}"
    template_name => "nodejs-logs"
    template => "/usr/share/logstash/templates/nodejs-logs.json"
    template_overwrite => true
  }
  
  # è°ƒè¯•è¾“å‡ºï¼ˆå¼€å‘ç¯å¢ƒï¼‰
  if [@metadata][debug] {
    stdout {
      codec => rubydebug
    }
  }
}
```

#### Kibanaä»ªè¡¨æ¿é…ç½®

```json
{
  "version": "8.10.0",
  "objects": [
    {
      "id": "nodejs-logs-dashboard",
      "type": "dashboard",
      "attributes": {
        "title": "Node.js Application Logs",
        "hits": 0,
        "description": "Dashboard for Node.js application logs",
        "panelsJSON": "[{\"version\":\"8.10.0\",\"gridData\":{\"x\":0,\"y\":0,\"w\":24,\"h\":15,\"i\":\"1\"},\"panelIndex\":\"1\",\"embeddableConfig\":{},\"panelRefName\":\"panel_1\"}]",
        "optionsJSON": "{\"useMargins\":true,\"syncColors\":false,\"hidePanelTitles\":false}",
        "uiStateJSON": "{}",
        "timeRestore": false,
        "kibanaSavedObjectMeta": {
          "searchSourceJSON": "{\"query\":{\"match_all\":{}},\"filter\":[]}"
        }
      }
    },
    {
      "id": "nodejs-logs-index-pattern",
      "type": "index-pattern",
      "attributes": {
        "title": "nodejs-logs-*",
        "timeFieldName": "@timestamp",
        "fields": "[{\"name\":\"@timestamp\",\"type\":\"date\",\"searchable\":true,\"aggregatable\":true},{\"name\":\"level\",\"type\":\"string\",\"searchable\":true,\"aggregatable\":true},{\"name\":\"message\",\"type\":\"string\",\"searchable\":true,\"aggregatable\":false},{\"name\":\"service\",\"type\":\"string\",\"searchable\":true,\"aggregatable\":true},{\"name\":\"traceId\",\"type\":\"string\",\"searchable\":true,\"aggregatable\":true}]"
      }
    }
  ]
}
```

### Fluentdé…ç½®

```ruby
# fluentd.conf
<source>
  @type tail
  path /var/log/nodejs/*.log
  pos_file /var/log/fluentd/nodejs.log.pos
  tag nodejs.app
  format json
  time_key timestamp
  time_format %Y-%m-%d %H:%M:%S.%L
</source>

<source>
  @type http
  port 9880
  bind 0.0.0.0
  tag nodejs.http
</source>

<filter nodejs.**>
  @type record_transformer
  <record>
    hostname ${hostname}
    environment #{ENV['ENVIRONMENT']}
  </record>
</filter>

<filter nodejs.**>
  @type grep
  <exclude>
    key message
    pattern /health/
  </exclude>
</filter>

<match nodejs.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  index_name nodejs-logs
  type_name _doc
  logstash_format true
  logstash_prefix nodejs-logs
  logstash_dateformat %Y.%m.%d
  include_tag_key true
  tag_key @log_name
  flush_interval 5s
</match>
```

## ğŸ” æ—¥å¿—åˆ†æå’Œç›‘æ§

### æ—¥å¿—åˆ†ææŸ¥è¯¢

```javascript
// æ—¥å¿—åˆ†æAPI
const { Client } = require('@elastic/elasticsearch');

class LogAnalyzer {
  constructor() {
    this.client = new Client({
      node: process.env.ELASTICSEARCH_URL || 'http://localhost:9200'
    });
  }
  
  // é”™è¯¯ç‡åˆ†æ
  async getErrorRate(timeRange = '1h') {
    const query = {
      index: 'nodejs-logs-*',
      body: {
        size: 0,
        query: {
          bool: {
            filter: [
              {
                range: {
                  '@timestamp': {
                    gte: `now-${timeRange}`
                  }
                }
              }
            ]
          }
        },
        aggs: {
          error_rate: {
            terms: {
              field: 'level.keyword'
            }
          }
        }
      }
    };
    
    const response = await this.client.search(query);
    return this.calculateErrorRate(response.body.aggregations.error_rate.buckets);
  }
  
  // å“åº”æ—¶é—´åˆ†æ
  async getResponseTimeStats(timeRange = '1h') {
    const query = {
      index: 'nodejs-logs-*',
      body: {
        size: 0,
        query: {
          bool: {
            filter: [
              {
                range: {
                  '@timestamp': {
                    gte: `now-${timeRange}`
                  }
                }
              },
              {
                exists: {
                  field: 'duration'
                }
              }
            ]
          }
        },
        aggs: {
          response_time_stats: {
            stats: {
              field: 'duration'
            }
          },
          response_time_percentiles: {
            percentiles: {
              field: 'duration',
              percents: [50, 90, 95, 99]
            }
          }
        }
      }
    };
    
    const response = await this.client.search(query);
    return {
      stats: response.body.aggregations.response_time_stats,
      percentiles: response.body.aggregations.response_time_percentiles.values
    };
  }
  
  // çƒ­é—¨APIç«¯ç‚¹
  async getTopEndpoints(timeRange = '1h', size = 10) {
    const query = {
      index: 'nodejs-logs-*',
      body: {
        size: 0,
        query: {
          bool: {
            filter: [
              {
                range: {
                  '@timestamp': {
                    gte: `now-${timeRange}`
                  }
                }
              },
              {
                exists: {
                  field: 'url'
                }
              }
            ]
          }
        },
        aggs: {
          top_endpoints: {
            terms: {
              field: 'url.keyword',
              size: size
            },
            aggs: {
              avg_response_time: {
                avg: {
                  field: 'duration'
                }
              },
              error_rate: {
                filter: {
                  range: {
                    statusCode: {
                      gte: 400
                    }
                  }
                }
              }
            }
          }
        }
      }
    };
    
    const response = await this.client.search(query);
    return response.body.aggregations.top_endpoints.buckets;
  }
  
  // ç”¨æˆ·æ´»åŠ¨åˆ†æ
  async getUserActivity(userId, timeRange = '24h') {
    const query = {
      index: 'nodejs-logs-*',
      body: {
        size: 100,
        query: {
          bool: {
            filter: [
              {
                range: {
                  '@timestamp': {
                    gte: `now-${timeRange}`
                  }
                }
              },
              {
                term: {
                  'userId.keyword': userId
                }
              }
            ]
          }
        },
        sort: [
          {
            '@timestamp': {
              order: 'desc'
            }
          }
        ]
      }
    };
    
    const response = await this.client.search(query);
    return response.body.hits.hits.map(hit => hit._source);
  }
  
  calculateErrorRate(buckets) {
    const total = buckets.reduce((sum, bucket) => sum + bucket.doc_count, 0);
    const errors = buckets
      .filter(bucket => bucket.key === 'ERROR')
      .reduce((sum, bucket) => sum + bucket.doc_count, 0);
    
    return {
      total,
      errors,
      errorRate: total > 0 ? (errors / total) * 100 : 0
    };
  }
}

module.exports = LogAnalyzer;
```

### æ—¥å¿—å‘Šè­¦é…ç½®

```yaml
# elastalert/rules/nodejs-error-rate.yml
name: High Error Rate Alert
type: percentage_match
index: nodejs-logs-*
timeframe:
  minutes: 10
buffer_time:
  minutes: 2

query_key: service.keyword
percentage_format_string: "{:.1%}"

match_bucket_filter:
  terms:
    level.keyword: ["ERROR", "FATAL"]

min_denominator: 50
max_percentage: 5

alert:
  - "email"
  - "slack"

email:
  - "devops@company.com"

slack:
webhook_url: "https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"
slack_channel_override: "#alerts"
slack_username_override: "ElastAlert"

alert_text: |
  Error rate for service {0} is {1:.1%} over the last 10 minutes.
  This exceeds the threshold of 5%.

alert_text_type: alert_text_only

include:
  - service
  - level
  - message
  - "@timestamp"
```

### æ—¥å¿—è½®è½¬é…ç½®

```bash
# /etc/logrotate.d/nodejs-app
/var/log/nodejs-app/*.log {
    daily
    missingok
    rotate 30
    compress
    delaycompress
    notifempty
    create 644 nodejs nodejs
    postrotate
        # é€šçŸ¥åº”ç”¨é‡æ–°æ‰“å¼€æ—¥å¿—æ–‡ä»¶
        /bin/kill -USR1 $(cat /var/run/nodejs-app.pid) 2>/dev/null || true
    endscript
}

# æ‰‹åŠ¨æ‰§è¡Œæ—¥å¿—è½®è½¬
sudo logrotate -f /etc/logrotate.d/nodejs-app
```

## ğŸš€ æ—¥å¿—ç®¡ç†æœ€ä½³å®è·µ

### ç»“æ„åŒ–æ—¥å¿—

```javascript
// å¥½çš„æ—¥å¿—å®è·µ
logger.info('User operation completed', {
  operation: 'user_update',
  userId: user.id,
  changes: ['email', 'profile'],
  duration: 150,
  success: true
});

// é¿å…çš„æ—¥å¿—å®è·µ
logger.info(`User ${user.id} updated email and profile in 150ms`);
```

### æ•æ„Ÿä¿¡æ¯è¿‡æ»¤

```javascript
function sanitizeLogData(data) {
  const sensitive = ['password', 'token', 'secret', 'key', 'authorization'];
  const sanitized = JSON.parse(JSON.stringify(data));
  
  function recursiveSanitize(obj) {
    for (const key in obj) {
      if (typeof obj[key] === 'object' && obj[key] !== null) {
        recursiveSanitize(obj[key]);
      } else if (sensitive.some(s => key.toLowerCase().includes(s))) {
        obj[key] = '[REDACTED]';
      }
    }
  }
  
  recursiveSanitize(sanitized);
  return sanitized;
}
```

### æ€§èƒ½ç›‘æ§

```javascript
// æ—¥å¿—æ€§èƒ½ç›‘æ§
class PerformanceLogger {
  static startTimer(operation) {
    return {
      operation,
      startTime: process.hrtime.bigint()
    };
  }
  
  static endTimer(timer, metadata = {}) {
    const endTime = process.hrtime.bigint();
    const duration = Number(endTime - timer.startTime) / 1000000; // è½¬æ¢ä¸ºæ¯«ç§’
    
    logger.info('Performance metric', {
      operation: timer.operation,
      duration,
      ...metadata
    });
    
    return duration;
  }
}

// ä½¿ç”¨ç¤ºä¾‹
const timer = PerformanceLogger.startTimer('database_query');
const results = await db.query(sql);
PerformanceLogger.endTimer(timer, { rowCount: results.length });
```

## ğŸ“ æ€»ç»“

æœ‰æ•ˆçš„æ—¥å¿—ç®¡ç†åº”è¯¥åŒ…æ‹¬ï¼š

- **ç»“æ„åŒ–æ—¥å¿—**ï¼šä¾¿äºæŸ¥è¯¢å’Œåˆ†æ
- **é€‚å½“çš„æ—¥å¿—çº§åˆ«**ï¼šå¹³è¡¡è¯¦ç»†ç¨‹åº¦å’Œæ€§èƒ½
- **æ•æ„Ÿä¿¡æ¯ä¿æŠ¤**ï¼šé¿å…æ³„éœ²æœºå¯†æ•°æ®
- **é›†ä¸­åŒ–æ”¶é›†**ï¼šç»Ÿä¸€ç®¡ç†å¤šä¸ªæœåŠ¡çš„æ—¥å¿—
- **å®æ—¶ç›‘æ§**ï¼šåŠæ—¶å‘ç°å’Œå“åº”é—®é¢˜
- **é•¿æœŸå­˜å‚¨**ï¼šæ»¡è¶³åˆè§„å’Œå®¡è®¡è¦æ±‚

è‰¯å¥½çš„æ—¥å¿—ç®¡ç†æ˜¯ç³»ç»Ÿå¯è§‚æµ‹æ€§çš„åŸºç¡€ï¼Œå¯¹äºé—®é¢˜æ’æŸ¥å’Œæ€§èƒ½ä¼˜åŒ–è‡³å…³é‡è¦ã€‚

## ğŸ”— ç›¸å…³èµ„æº

- [Winstonæ–‡æ¡£](https://github.com/winstonjs/winston)
- [ELK StackæŒ‡å—](https://www.elastic.co/guide/index.html)
- [Fluentdæ–‡æ¡£](https://docs.fluentd.org/)
- [æ—¥å¿—ç®¡ç†æœ€ä½³å®è·µ](https://www.loggly.com/ultimate-guide/node-logging-basics/)
