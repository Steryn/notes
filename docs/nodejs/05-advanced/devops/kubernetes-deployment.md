# Kuberneteséƒ¨ç½²

## ğŸ“‹ æ¦‚è¿°

Kubernetesæ˜¯ä¸€ä¸ªå¼€æºçš„å®¹å™¨ç¼–æ’å¹³å°ï¼Œç”¨äºè‡ªåŠ¨åŒ–éƒ¨ç½²ã€æ‰©å±•å’Œç®¡ç†å®¹å™¨åŒ–åº”ç”¨ç¨‹åºã€‚å®ƒæä¾›äº†å¼ºå¤§çš„æœåŠ¡å‘ç°ã€è´Ÿè½½å‡è¡¡ã€è‡ªåŠ¨æ‰©ç¼©å®¹ç­‰åŠŸèƒ½ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- ç†è§£Kubernetesçš„æ ¸å¿ƒæ¦‚å¿µå’Œæ¶æ„
- æŒæ¡Node.jsåº”ç”¨çš„Kuberneteséƒ¨ç½²
- å­¦ä¼šç¼–å†™Kubernetesé…ç½®æ–‡ä»¶
- äº†è§£æœåŠ¡ç½‘æ ¼å’Œç›‘æ§é…ç½®

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µ

### Podï¼ˆå®¹å™¨ç»„ï¼‰

Kubernetesä¸­æœ€å°çš„éƒ¨ç½²å•å…ƒï¼ŒåŒ…å«ä¸€ä¸ªæˆ–å¤šä¸ªå®¹å™¨ã€‚

```yaml
# pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: node-app-pod
  labels:
    app: node-app
spec:
  containers:
  - name: app
    image: node-app:latest
    ports:
    - containerPort: 3000
    env:
    - name: NODE_ENV
      value: "production"
```

### Deploymentï¼ˆéƒ¨ç½²ï¼‰

ç®¡ç†Podçš„å‰¯æœ¬å’Œæ›´æ–°ç­–ç•¥ã€‚

```yaml
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-app-deployment
  labels:
    app: node-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: node-app
  template:
    metadata:
      labels:
        app: node-app
    spec:
      containers:
      - name: app
        image: node-app:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
```

### Serviceï¼ˆæœåŠ¡ï¼‰

ä¸ºPodæä¾›ç¨³å®šçš„ç½‘ç»œç«¯ç‚¹ã€‚

```yaml
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: node-app-service
spec:
  selector:
    app: node-app
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: ClusterIP
```

### Ingressï¼ˆå…¥å£ï¼‰

ç®¡ç†å¤–éƒ¨è®¿é—®åˆ°é›†ç¾¤å†…æœåŠ¡çš„HTTPå’ŒHTTPSè·¯ç”±ã€‚

```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: node-app-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  tls:
  - hosts:
    - api.example.com
    secretName: api-tls
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: node-app-service
            port:
              number: 80
```

## ğŸ›  å®Œæ•´Node.jsåº”ç”¨éƒ¨ç½²

### åº”ç”¨é…ç½®

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: node-app

---
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: node-app-config
  namespace: node-app
data:
  NODE_ENV: "production"
  LOG_LEVEL: "info"
  PORT: "3000"

---
# secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: node-app-secrets
  namespace: node-app
type: Opaque
data:
  database-url: cG9zdGdyZXM6Ly91c2VyOnBhc3N3b3JkQHBvc3RncmVzOjU0MzIvbXlhcHA=
  jwt-secret: eW91ci1qd3Qtc2VjcmV0LWtleQ==
  redis-url: cmVkaXM6Ly9yZWRpczozNjM3OQ==

---
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-app
  namespace: node-app
  labels:
    app: node-app
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: node-app
  template:
    metadata:
      labels:
        app: node-app
        version: v1
    spec:
      containers:
      - name: app
        image: node-app:1.0.0
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: NODE_ENV
          valueFrom:
            configMapKeyRef:
              name: node-app-config
              key: NODE_ENV
        - name: PORT
          valueFrom:
            configMapKeyRef:
              name: node-app-config
              key: PORT
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: node-app-secrets
              key: database-url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: node-app-secrets
              key: jwt-secret
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: node-app-secrets
              key: redis-url
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        volumeMounts:
        - name: app-logs
          mountPath: /usr/src/app/logs
      volumes:
      - name: app-logs
        emptyDir: {}
      imagePullSecrets:
      - name: registry-secret

---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: node-app-service
  namespace: node-app
  labels:
    app: node-app
spec:
  selector:
    app: node-app
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 3000
  type: ClusterIP

---
# hpa.yaml (Horizontal Pod Autoscaler)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: node-app-hpa
  namespace: node-app
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: node-app
  minReplicas: 3
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80

---
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: node-app-ingress
  namespace: node-app
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
spec:
  tls:
  - hosts:
    - api.example.com
    secretName: node-app-tls
  rules:
  - host: api.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: node-app-service
            port:
              number: 80
```

### æ•°æ®åº“éƒ¨ç½²

```yaml
# postgres-deployment.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pvc
  namespace: node-app
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: ssd

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: node-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:13-alpine
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          value: myapp
        - name: POSTGRES_USER
          value: user
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - pg_isready
            - -U
            - user
            - -d
            - myapp
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: postgres-storage
        persistentVolumeClaim:
          claimName: postgres-pvc

---
apiVersion: v1
kind: Service
metadata:
  name: postgres
  namespace: node-app
spec:
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432
  type: ClusterIP

---
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: node-app
type: Opaque
data:
  password: cGFzc3dvcmQ=  # base64 encoded 'password'
```

### Rediséƒ¨ç½²

```yaml
# redis-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: node-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        command: ["redis-server"]
        args: ["--appendonly", "yes"]
        volumeMounts:
        - name: redis-storage
          mountPath: /data
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: redis-storage
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: node-app
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
  type: ClusterIP
```

## ğŸ”§ é«˜çº§é…ç½®

### æ»šåŠ¨æ›´æ–°ç­–ç•¥

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: node-app
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    spec:
      containers:
      - name: app
        image: node-app:1.1.0
        # ä¼˜é›…å…³é—­é…ç½®
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
        # ç»ˆæ­¢å®½é™æœŸ
      terminationGracePeriodSeconds: 30
```

### è“ç»¿éƒ¨ç½²

```yaml
# blue-green-deployment.yaml
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: node-app-rollout
  namespace: node-app
spec:
  replicas: 5
  strategy:
    blueGreen:
      activeService: node-app-active
      previewService: node-app-preview
      autoPromotionEnabled: false
      scaleDownDelaySeconds: 30
      prePromotionAnalysis:
        templates:
        - templateName: success-rate
        args:
        - name: service-name
          value: node-app-preview
      postPromotionAnalysis:
        templates:
        - templateName: success-rate
        args:
        - name: service-name
          value: node-app-active
  selector:
    matchLabels:
      app: node-app
  template:
    metadata:
      labels:
        app: node-app
    spec:
      containers:
      - name: app
        image: node-app:1.2.0
```

### é‡‘ä¸é›€éƒ¨ç½²

```yaml
# canary-deployment.yaml
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: node-app-canary
  namespace: node-app
spec:
  replicas: 10
  strategy:
    canary:
      steps:
      - setWeight: 10
      - pause: {duration: 1m}
      - setWeight: 20
      - pause: {duration: 1m}
      - setWeight: 50
      - pause: {duration: 1m}
      - setWeight: 100
      canaryService: node-app-canary
      stableService: node-app-stable
      trafficRouting:
        nginx:
          stableIngress: node-app-ingress
  selector:
    matchLabels:
      app: node-app
  template:
    metadata:
      labels:
        app: node-app
    spec:
      containers:
      - name: app
        image: node-app:1.3.0
```

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### Prometheusç›‘æ§

```yaml
# monitoring.yaml
apiVersion: v1
kind: ServiceMonitor
metadata:
  name: node-app-metrics
  namespace: node-app
  labels:
    app: node-app
spec:
  selector:
    matchLabels:
      app: node-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics

---
apiVersion: v1
kind: Service
metadata:
  name: node-app-metrics
  namespace: node-app
  labels:
    app: node-app
spec:
  selector:
    app: node-app
  ports:
  - name: metrics
    port: 9090
    targetPort: 9090

---
# PrometheusRule for alerting
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: node-app-alerts
  namespace: node-app
spec:
  groups:
  - name: node-app
    rules:
    - alert: NodeAppDown
      expr: up{job="node-app"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Node.js application is down"
        description: "Node.js application has been down for more than 1 minute"
    
    - alert: NodeAppHighErrorRate
      expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High error rate detected"
        description: "Error rate is above 10% for 5 minutes"
    
    - alert: NodeAppHighMemoryUsage
      expr: container_memory_usage_bytes{pod=~"node-app-.*"} / container_spec_memory_limit_bytes > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High memory usage"
        description: "Memory usage is above 80% for 5 minutes"
```

### æ—¥å¿—æ”¶é›†

```yaml
# fluentd-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: kube-system
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/node-app-*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      format json
    </source>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch.logging.svc.cluster.local
      port 9200
      index_name kubernetes
      type_name fluentd
    </match>

---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch.logging.svc.cluster.local"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluentd-config
```

## ğŸš€ éƒ¨ç½²å’Œç®¡ç†

### éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy.sh

set -e

NAMESPACE="node-app"
IMAGE_TAG=${1:-latest}

echo "ğŸš€ Deploying Node.js application to Kubernetes..."

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# åº”ç”¨é…ç½®
echo "ğŸ“¦ Applying configurations..."
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secrets.yaml

# éƒ¨ç½²æ•°æ®åº“
echo "ğŸ’¾ Deploying database..."
kubectl apply -f k8s/postgres-deployment.yaml
kubectl apply -f k8s/redis-deployment.yaml

# ç­‰å¾…æ•°æ®åº“å°±ç»ª
echo "â³ Waiting for database to be ready..."
kubectl wait --for=condition=ready pod -l app=postgres -n $NAMESPACE --timeout=300s
kubectl wait --for=condition=ready pod -l app=redis -n $NAMESPACE --timeout=300s

# æ›´æ–°åº”ç”¨é•œåƒæ ‡ç­¾
sed -i "s|node-app:.*|node-app:$IMAGE_TAG|g" k8s/deployment.yaml

# éƒ¨ç½²åº”ç”¨
echo "ğŸš€ Deploying application..."
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml
kubectl apply -f k8s/ingress.yaml
kubectl apply -f k8s/hpa.yaml

# ç­‰å¾…éƒ¨ç½²å®Œæˆ
echo "â³ Waiting for deployment to complete..."
kubectl rollout status deployment/node-app -n $NAMESPACE --timeout=600s

# éªŒè¯éƒ¨ç½²
echo "ğŸ” Verifying deployment..."
kubectl get pods -n $NAMESPACE
kubectl get services -n $NAMESPACE
kubectl get ingress -n $NAMESPACE

echo "âœ… Deployment completed successfully!"
```

### å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# health-check.sh

NAMESPACE="node-app"
SERVICE_URL="https://api.example.com"

echo "ğŸ” Performing health checks..."

# æ£€æŸ¥PodçŠ¶æ€
echo "ğŸ“Š Checking pod status..."
READY_PODS=$(kubectl get pods -n $NAMESPACE -l app=node-app -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}' | tr ' ' '\n' | grep -c "True")
TOTAL_PODS=$(kubectl get pods -n $NAMESPACE -l app=node-app --no-headers | wc -l)

echo "Ready pods: $READY_PODS/$TOTAL_PODS"

if [ "$READY_PODS" -eq "$TOTAL_PODS" ] && [ "$TOTAL_PODS" -gt 0 ]; then
    echo "âœ… All pods are ready"
else
    echo "âŒ Some pods are not ready"
    kubectl get pods -n $NAMESPACE -l app=node-app
    exit 1
fi

# æ£€æŸ¥æœåŠ¡ç«¯ç‚¹
echo "ğŸŒ Checking service endpoints..."
if curl -f -s "$SERVICE_URL/health" > /dev/null; then
    echo "âœ… Service is responding"
else
    echo "âŒ Service is not responding"
    exit 1
fi

# æ£€æŸ¥HPAçŠ¶æ€
echo "ğŸ“ˆ Checking HPA status..."
kubectl get hpa -n $NAMESPACE

echo "ğŸ‰ All health checks passed!"
```

### å›æ»šè„šæœ¬

```bash
#!/bin/bash
# rollback.sh

NAMESPACE="node-app"
REVISION=${1:-}

echo "ğŸ”„ Rolling back deployment..."

if [ -n "$REVISION" ]; then
    kubectl rollout undo deployment/node-app -n $NAMESPACE --to-revision=$REVISION
else
    kubectl rollout undo deployment/node-app -n $NAMESPACE
fi

echo "â³ Waiting for rollback to complete..."
kubectl rollout status deployment/node-app -n $NAMESPACE --timeout=600s

echo "âœ… Rollback completed successfully!"
```

## ğŸ” æ•…éšœæ’é™¤

### å¸¸ç”¨è°ƒè¯•å‘½ä»¤

```bash
# æŸ¥çœ‹PodçŠ¶æ€
kubectl get pods -n node-app
kubectl describe pod <pod-name> -n node-app

# æŸ¥çœ‹Podæ—¥å¿—
kubectl logs <pod-name> -n node-app -f
kubectl logs -l app=node-app -n node-app --tail=100

# è¿›å…¥Podè°ƒè¯•
kubectl exec -it <pod-name> -n node-app -- sh

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
kubectl get svc -n node-app
kubectl describe svc node-app-service -n node-app

# æŸ¥çœ‹IngressçŠ¶æ€
kubectl get ingress -n node-app
kubectl describe ingress node-app-ingress -n node-app

# æŸ¥çœ‹äº‹ä»¶
kubectl get events -n node-app --sort-by=.metadata.creationTimestamp

# æŸ¥çœ‹èµ„æºä½¿ç”¨æƒ…å†µ
kubectl top pods -n node-app
kubectl top nodes
```

### å¸¸è§é—®é¢˜è§£å†³

#### 1. Podå¯åŠ¨å¤±è´¥

```bash
# æ£€æŸ¥PodçŠ¶æ€å’Œäº‹ä»¶
kubectl describe pod <pod-name> -n node-app

# å¸¸è§åŸå› ï¼š
# - é•œåƒæ‹‰å–å¤±è´¥
# - èµ„æºä¸è¶³
# - é…ç½®é”™è¯¯
# - å¥åº·æ£€æŸ¥å¤±è´¥
```

#### 2. æœåŠ¡æ— æ³•è®¿é—®

```bash
# æ£€æŸ¥æœåŠ¡ç«¯ç‚¹
kubectl get endpoints -n node-app

# æ£€æŸ¥ç½‘ç»œç­–ç•¥
kubectl get networkpolicies -n node-app

# æµ‹è¯•æœåŠ¡è¿æ¥
kubectl run test-pod --image=busybox -it --rm -- sh
# åœ¨Podå†…æµ‹è¯•ï¼šwget -qO- http://node-app-service/health
```

#### 3. æ•°æ®åº“è¿æ¥é—®é¢˜

```bash
# æ£€æŸ¥æ•°æ®åº“PodçŠ¶æ€
kubectl get pods -l app=postgres -n node-app

# æµ‹è¯•æ•°æ®åº“è¿æ¥
kubectl exec -it <postgres-pod> -n node-app -- psql -U user -d myapp -c "SELECT 1;"

# æ£€æŸ¥DNSè§£æ
kubectl exec -it <app-pod> -n node-app -- nslookup postgres
```

## ğŸ“ æ€»ç»“

Kubernetesä¸ºNode.jsåº”ç”¨æä¾›äº†å¼ºå¤§çš„å®¹å™¨ç¼–æ’èƒ½åŠ›ï¼š

- **é«˜å¯ç”¨æ€§**ï¼šå¤šå‰¯æœ¬å’Œè‡ªåŠ¨æ•…éšœæ¢å¤
- **å¼¹æ€§æ‰©ç¼©å®¹**ï¼šæ ¹æ®è´Ÿè½½è‡ªåŠ¨è°ƒæ•´å®ä¾‹æ•°é‡
- **æœåŠ¡å‘ç°**ï¼šå†…ç½®çš„DNSå’Œè´Ÿè½½å‡è¡¡
- **æ»šåŠ¨æ›´æ–°**ï¼šé›¶åœæœºæ—¶é—´çš„åº”ç”¨æ›´æ–°
- **ç›‘æ§å’Œæ—¥å¿—**ï¼šå®Œæ•´çš„å¯è§‚æµ‹æ€§è§£å†³æ–¹æ¡ˆ

æ˜¯ç°ä»£äº‘åŸç”Ÿåº”ç”¨éƒ¨ç½²çš„é¦–é€‰å¹³å°ã€‚

## ğŸ”— ç›¸å…³èµ„æº

- [Kuberneteså®˜æ–¹æ–‡æ¡£](https://kubernetes.io/docs/)
- [kubectlå‘½ä»¤å‚è€ƒ](https://kubernetes.io/docs/reference/kubectl/)
- [Kubernetesæœ€ä½³å®è·µ](https://kubernetes.io/docs/concepts/configuration/overview/)
- [Node.js on Kubernetes](https://nodejs.org/en/docs/guides/nodejs-docker-webapp/)
