# æ•°æ®åº“æµ‹è¯•

## ğŸ“‹ æ¦‚è¿°

æ•°æ®åº“æµ‹è¯•æ˜¯éªŒè¯æ•°æ®æŒä¹…åŒ–å±‚åŠŸèƒ½ã€æ€§èƒ½å’Œæ•°æ®å®Œæ•´æ€§çš„å…³é”®æµ‹è¯•ç¯èŠ‚ã€‚åœ¨Node.jsåº”ç”¨ä¸­ï¼Œæ•°æ®åº“æµ‹è¯•ç¡®ä¿æ•°æ®è®¿é—®å±‚ï¼ˆDALï¼‰ã€ORMæ“ä½œã€äº‹åŠ¡å¤„ç†ã€æ•°æ®è¿ç§»ç­‰åŠŸèƒ½æ­£ç¡®æ— è¯¯ï¼Œæ˜¯æ„å»ºå¯é æ•°æ®é©±åŠ¨åº”ç”¨çš„åŸºç¡€ã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- ç†è§£æ•°æ®åº“æµ‹è¯•çš„æ ¸å¿ƒæ¦‚å¿µå’Œç­–ç•¥
- æŒæ¡ä¸åŒç±»å‹æ•°æ®åº“çš„æµ‹è¯•æ–¹æ³•
- å­¦ä¼šè®¾è®¡æ•°æ®åº“æµ‹è¯•ç¯å¢ƒå’Œæ•°æ®ç®¡ç†
- äº†è§£æ•°æ®åº“æ€§èƒ½æµ‹è¯•å’Œä¼˜åŒ–éªŒè¯

## ğŸ—„ï¸ æ•°æ®åº“æµ‹è¯•ç±»å‹

### æ•°æ®åº“æµ‹è¯•åˆ†ç±»

```mermaid
graph TB
    A[æ•°æ®åº“æµ‹è¯•ç±»å‹] --> B[åŠŸèƒ½æµ‹è¯•<br/>Functional Testing]
    A --> C[æ€§èƒ½æµ‹è¯•<br/>Performance Testing]
    A --> D[æ•°æ®å®Œæ•´æ€§æµ‹è¯•<br/>Data Integrity Testing]
    A --> E[å®‰å…¨æµ‹è¯•<br/>Security Testing]
    
    B --> B1[CRUDæ“ä½œ<br/>æŸ¥è¯¢åŠŸèƒ½<br/>å­˜å‚¨è¿‡ç¨‹<br/>è§¦å‘å™¨]
    C --> C1[æŸ¥è¯¢æ€§èƒ½<br/>å¹¶å‘è®¿é—®<br/>å¤§æ•°æ®é‡<br/>ç´¢å¼•æ•ˆç‡]
    D --> D1[çº¦æŸéªŒè¯<br/>äº‹åŠ¡ä¸€è‡´æ€§<br/>æ•°æ®å…³ç³»<br/>æ•°æ®ç±»å‹]
    E --> E1[è®¿é—®æ§åˆ¶<br/>SQLæ³¨å…¥<br/>æ•°æ®åŠ å¯†<br/>å®¡è®¡æ—¥å¿—]
    
    style B fill:#e1f5fe
    style C fill:#f3e5f5
    style D fill:#e8f5e8
    style E fill:#ffebee
```

### æµ‹è¯•å±‚çº§ç­–ç•¥

```javascript
const DatabaseTestingStrategy = {
  UNIT_LEVEL: {
    scope: 'å•ä¸ªæ•°æ®è®¿é—®æ–¹æ³•',
    focus: [
      'å•ä¸€è¡¨çš„CRUDæ“ä½œ',
      'ç®€å•æŸ¥è¯¢é€»è¾‘éªŒè¯',
      'æ•°æ®æ˜ å°„æ­£ç¡®æ€§',
      'å‚æ•°ç»‘å®šå®‰å…¨æ€§'
    ],
    tools: ['Jest', 'Mocha', 'In-memory DB'],
    characteristics: [
      'å¿«é€Ÿæ‰§è¡Œ',
      'éš”ç¦»æµ‹è¯•',
      'æ¨¡æ‹Ÿæ•°æ®',
      'ä¸“æ³¨å•ä¸€åŠŸèƒ½'
    ]
  },
  
  INTEGRATION_LEVEL: {
    scope: 'æ•°æ®è®¿é—®å±‚ä¸ä¸šåŠ¡é€»è¾‘é›†æˆ',
    focus: [
      'å¤šè¡¨è”åˆæŸ¥è¯¢',
      'äº‹åŠ¡è¾¹ç•ŒéªŒè¯',
      'æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥',
      'å¤–é”®çº¦æŸéªŒè¯'
    ],
    tools: ['Test Containers', 'Database Fixtures', 'Migration Scripts'],
    characteristics: [
      'çœŸå®æ•°æ®åº“ç¯å¢ƒ',
      'å®Œæ•´æ•°æ®æµéªŒè¯',
      'ä¸šåŠ¡åœºæ™¯è¦†ç›–',
      'ç¯å¢ƒæ¥è¿‘ç”Ÿäº§'
    ]
  },
  
  SYSTEM_LEVEL: {
    scope: 'å®Œæ•´ç³»ç»Ÿçš„æ•°æ®åº“äº¤äº’',
    focus: [
      'ç«¯åˆ°ç«¯æ•°æ®æµ',
      'å¹¶å‘æ•°æ®è®¿é—®',
      'å¤§æ•°æ®é‡å¤„ç†',
      'å¤‡ä»½æ¢å¤éªŒè¯'
    ],
    tools: ['Load Testing Tools', 'Monitoring Solutions', 'Backup Tools'],
    characteristics: [
      'ç”Ÿäº§ç¯å¢ƒæ¨¡æ‹Ÿ',
      'æ€§èƒ½åŸºå‡†éªŒè¯',
      'å®¹ç¾èƒ½åŠ›æµ‹è¯•',
      'è¿ç»´åœºæ™¯è¦†ç›–'
    ]
  }
};
```

## ğŸ›  æ•°æ®åº“æµ‹è¯•ç¯å¢ƒè®¾ç½®

### å¤šæ•°æ®åº“æµ‹è¯•é…ç½®

```javascript
// database-test-manager.js
const { Pool } = require('pg');
const mongoose = require('mongoose');
const { MongoMemoryServer } = require('mongodb-memory-server');
const mysql = require('mysql2/promise');
const redis = require('redis');

class DatabaseTestManager {
  constructor() {
    this.connections = new Map();
    this.testDatabases = [];
    this.mongoServer = null;
    this.redisClient = null;
  }
  
  // PostgreSQLæµ‹è¯•ç¯å¢ƒ
  async setupPostgreSQL(config = {}) {
    const defaultConfig = {
      user: process.env.TEST_PG_USER || 'test_user',
      host: process.env.TEST_PG_HOST || 'localhost',
      password: process.env.TEST_PG_PASSWORD || 'test_password',
      port: process.env.TEST_PG_PORT || 5432,
      database: `test_db_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    };
    
    const testConfig = { ...defaultConfig, ...config };
    
    // åˆ›å»ºæµ‹è¯•æ•°æ®åº“
    const adminPool = new Pool({
      ...testConfig,
      database: 'postgres'
    });
    
    try {
      await adminPool.query(`CREATE DATABASE "${testConfig.database}"`);
      console.log(`âœ… PostgreSQL test database created: ${testConfig.database}`);
    } catch (error) {
      console.warn('âš ï¸  PostgreSQL database creation warning:', error.message);
    } finally {
      await adminPool.end();
    }
    
    // è¿æ¥åˆ°æµ‹è¯•æ•°æ®åº“
    const testPool = new Pool(testConfig);
    this.connections.set('postgresql', testPool);
    
    this.testDatabases.push({
      type: 'postgresql',
      name: testConfig.database,
      connection: testPool,
      config: testConfig
    });
    
    // åˆå§‹åŒ–æ•°æ®åº“ç»“æ„
    await this.initializePostgreSQLSchema(testPool);
    
    return testPool;
  }
  
  // MySQLæµ‹è¯•ç¯å¢ƒ
  async setupMySQL(config = {}) {
    const defaultConfig = {
      host: process.env.TEST_MYSQL_HOST || 'localhost',
      user: process.env.TEST_MYSQL_USER || 'test_user',
      password: process.env.TEST_MYSQL_PASSWORD || 'test_password',
      port: process.env.TEST_MYSQL_PORT || 3306,
      database: `test_db_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
    };
    
    const testConfig = { ...defaultConfig, ...config };
    
    // åˆ›å»ºæµ‹è¯•æ•°æ®åº“
    const adminConnection = await mysql.createConnection({
      ...testConfig,
      database: undefined
    });
    
    try {
      await adminConnection.execute(`CREATE DATABASE \`${testConfig.database}\``);
      console.log(`âœ… MySQL test database created: ${testConfig.database}`);
    } catch (error) {
      console.warn('âš ï¸  MySQL database creation warning:', error.message);
    } finally {
      await adminConnection.end();
    }
    
    // è¿æ¥åˆ°æµ‹è¯•æ•°æ®åº“
    const testConnection = await mysql.createConnection(testConfig);
    this.connections.set('mysql', testConnection);
    
    this.testDatabases.push({
      type: 'mysql',
      name: testConfig.database,
      connection: testConnection,
      config: testConfig
    });
    
    // åˆå§‹åŒ–æ•°æ®åº“ç»“æ„
    await this.initializeMySQLSchema(testConnection);
    
    return testConnection;
  }
  
  // MongoDBæµ‹è¯•ç¯å¢ƒ
  async setupMongoDB(config = {}) {
    const defaultConfig = {
      dbName: `test_db_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      storageEngine: 'wiredTiger'
    };
    
    const testConfig = { ...defaultConfig, ...config };
    
    // å¯åŠ¨å†…å­˜MongoDBæœåŠ¡å™¨
    this.mongoServer = await MongoMemoryServer.create({
      instance: {
        dbName: testConfig.dbName,
        storageEngine: testConfig.storageEngine
      }
    });
    
    const mongoUri = this.mongoServer.getUri();
    
    // è¿æ¥åˆ°MongoDB
    const connection = await mongoose.createConnection(mongoUri);
    this.connections.set('mongodb', connection);
    
    this.testDatabases.push({
      type: 'mongodb',
      uri: mongoUri,
      connection: connection,
      server: this.mongoServer
    });
    
    // åˆå§‹åŒ–MongoDBé›†åˆå’Œç´¢å¼•
    await this.initializeMongoDBSchema(connection);
    
    console.log(`âœ… MongoDB test server started: ${mongoUri}`);
    return connection;
  }
  
  // Redisæµ‹è¯•ç¯å¢ƒ
  async setupRedis(config = {}) {
    const defaultConfig = {
      host: process.env.TEST_REDIS_HOST || 'localhost',
      port: process.env.TEST_REDIS_PORT || 6379,
      db: Math.floor(Math.random() * 15) + 1 // ä½¿ç”¨éšæœºæ•°æ®åº“ç¼–å·
    };
    
    const testConfig = { ...defaultConfig, ...config };
    
    this.redisClient = redis.createClient(testConfig);
    await this.redisClient.connect();
    
    this.connections.set('redis', this.redisClient);
    
    this.testDatabases.push({
      type: 'redis',
      client: this.redisClient,
      config: testConfig
    });
    
    console.log(`âœ… Redis test connection established: db${testConfig.db}`);
    return this.redisClient;
  }
  
  // PostgreSQLæ¶æ„åˆå§‹åŒ–
  async initializePostgreSQLSchema(pool) {
    const schemas = [
      // ç”¨æˆ·è¡¨
      `
        CREATE TABLE IF NOT EXISTS users (
          id SERIAL PRIMARY KEY,
          username VARCHAR(50) UNIQUE NOT NULL,
          email VARCHAR(100) UNIQUE NOT NULL,
          password_hash VARCHAR(255) NOT NULL,
          first_name VARCHAR(50),
          last_name VARCHAR(50),
          date_of_birth DATE,
          is_active BOOLEAN DEFAULT true,
          created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
          updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        )
      `,
      
      // åˆ†ç±»è¡¨
      `
        CREATE TABLE IF NOT EXISTS categories (
          id SERIAL PRIMARY KEY,
          name VARCHAR(100) NOT NULL,
          description TEXT,
          parent_id INTEGER REFERENCES categories(id),
          is_active BOOLEAN DEFAULT true,
          created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        )
      `,
      
      // äº§å“è¡¨
      `
        CREATE TABLE IF NOT EXISTS products (
          id SERIAL PRIMARY KEY,
          name VARCHAR(200) NOT NULL,
          description TEXT,
          price DECIMAL(10,2) NOT NULL CHECK (price >= 0),
          category_id INTEGER REFERENCES categories(id),
          stock_quantity INTEGER DEFAULT 0 CHECK (stock_quantity >= 0),
          sku VARCHAR(50) UNIQUE,
          is_available BOOLEAN DEFAULT true,
          created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
          updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        )
      `,
      
      // è®¢å•è¡¨
      `
        CREATE TABLE IF NOT EXISTS orders (
          id SERIAL PRIMARY KEY,
          user_id INTEGER NOT NULL REFERENCES users(id),
          order_number VARCHAR(50) UNIQUE NOT NULL,
          status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'confirmed', 'processing', 'shipped', 'delivered', 'cancelled')),
          total_amount DECIMAL(10,2) NOT NULL CHECK (total_amount >= 0),
          shipping_address JSONB,
          billing_address JSONB,
          created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
          updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        )
      `,
      
      // è®¢å•é¡¹è¡¨
      `
        CREATE TABLE IF NOT EXISTS order_items (
          id SERIAL PRIMARY KEY,
          order_id INTEGER NOT NULL REFERENCES orders(id) ON DELETE CASCADE,
          product_id INTEGER NOT NULL REFERENCES products(id),
          quantity INTEGER NOT NULL CHECK (quantity > 0),
          unit_price DECIMAL(10,2) NOT NULL CHECK (unit_price >= 0),
          total_price DECIMAL(10,2) GENERATED ALWAYS AS (quantity * unit_price) STORED,
          created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
        )
      `,
      
      // åˆ›å»ºç´¢å¼•
      `
        CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
        CREATE INDEX IF NOT EXISTS idx_users_username ON users(username);
        CREATE INDEX IF NOT EXISTS idx_users_active ON users(is_active);
        CREATE INDEX IF NOT EXISTS idx_products_category ON products(category_id);
        CREATE INDEX IF NOT EXISTS idx_products_sku ON products(sku);
        CREATE INDEX IF NOT EXISTS idx_products_available ON products(is_available);
        CREATE INDEX IF NOT EXISTS idx_orders_user ON orders(user_id);
        CREATE INDEX IF NOT EXISTS idx_orders_status ON orders(status);
        CREATE INDEX IF NOT EXISTS idx_orders_created ON orders(created_at);
        CREATE INDEX IF NOT EXISTS idx_order_items_order ON order_items(order_id);
        CREATE INDEX IF NOT EXISTS idx_order_items_product ON order_items(product_id);
      `,
      
      // åˆ›å»ºè§¦å‘å™¨æ›´æ–°updated_atå­—æ®µ
      `
        CREATE OR REPLACE FUNCTION update_updated_at_column()
        RETURNS TRIGGER AS $$
        BEGIN
          NEW.updated_at = CURRENT_TIMESTAMP;
          RETURN NEW;
        END;
        $$ language 'plpgsql';
        
        DROP TRIGGER IF EXISTS update_users_updated_at ON users;
        CREATE TRIGGER update_users_updated_at
          BEFORE UPDATE ON users
          FOR EACH ROW
          EXECUTE FUNCTION update_updated_at_column();
          
        DROP TRIGGER IF EXISTS update_products_updated_at ON products;
        CREATE TRIGGER update_products_updated_at
          BEFORE UPDATE ON products
          FOR EACH ROW
          EXECUTE FUNCTION update_updated_at_column();
          
        DROP TRIGGER IF EXISTS update_orders_updated_at ON orders;
        CREATE TRIGGER update_orders_updated_at
          BEFORE UPDATE ON orders
          FOR EACH ROW
          EXECUTE FUNCTION update_updated_at_column();
      `
    ];
    
    for (const schema of schemas) {
      try {
        await pool.query(schema);
      } catch (error) {
        console.warn('Schema creation warning:', error.message);
      }
    }
    
    console.log('âœ… PostgreSQL schema initialized');
  }
  
  // MySQLæ¶æ„åˆå§‹åŒ–
  async initializeMySQLSchema(connection) {
    const schemas = [
      `
        CREATE TABLE IF NOT EXISTS users (
          id INT AUTO_INCREMENT PRIMARY KEY,
          username VARCHAR(50) UNIQUE NOT NULL,
          email VARCHAR(100) UNIQUE NOT NULL,
          password_hash VARCHAR(255) NOT NULL,
          first_name VARCHAR(50),
          last_name VARCHAR(50),
          date_of_birth DATE,
          is_active BOOLEAN DEFAULT true,
          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
        )
      `,
      
      `
        CREATE TABLE IF NOT EXISTS categories (
          id INT AUTO_INCREMENT PRIMARY KEY,
          name VARCHAR(100) NOT NULL,
          description TEXT,
          parent_id INT,
          is_active BOOLEAN DEFAULT true,
          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          FOREIGN KEY (parent_id) REFERENCES categories(id)
        )
      `,
      
      `
        CREATE TABLE IF NOT EXISTS products (
          id INT AUTO_INCREMENT PRIMARY KEY,
          name VARCHAR(200) NOT NULL,
          description TEXT,
          price DECIMAL(10,2) NOT NULL CHECK (price >= 0),
          category_id INT,
          stock_quantity INT DEFAULT 0 CHECK (stock_quantity >= 0),
          sku VARCHAR(50) UNIQUE,
          is_available BOOLEAN DEFAULT true,
          created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
          updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
          FOREIGN KEY (category_id) REFERENCES categories(id)
        )
      `,
      
      `
        CREATE INDEX idx_users_email ON users(email);
        CREATE INDEX idx_products_category ON products(category_id);
        CREATE INDEX idx_products_sku ON products(sku);
      `
    ];
    
    for (const schema of schemas) {
      try {
        await connection.execute(schema);
      } catch (error) {
        console.warn('MySQL schema creation warning:', error.message);
      }
    }
    
    console.log('âœ… MySQL schema initialized');
  }
  
  // MongoDBæ¶æ„åˆå§‹åŒ–
  async initializeMongoDBSchema(connection) {
    // å®šä¹‰ç”¨æˆ·æ¨¡å¼
    const userSchema = new mongoose.Schema({
      username: { type: String, required: true, unique: true },
      email: { type: String, required: true, unique: true },
      passwordHash: { type: String, required: true },
      firstName: String,
      lastName: String,
      dateOfBirth: Date,
      isActive: { type: Boolean, default: true },
      profile: {
        avatar: String,
        bio: String,
        preferences: mongoose.Schema.Types.Mixed
      }
    }, {
      timestamps: true,
      collection: 'users'
    });
    
    // äº§å“æ¨¡å¼
    const productSchema = new mongoose.Schema({
      name: { type: String, required: true },
      description: String,
      price: { type: Number, required: true, min: 0 },
      category: { type: mongoose.Schema.Types.ObjectId, ref: 'Category' },
      stockQuantity: { type: Number, default: 0, min: 0 },
      sku: { type: String, unique: true, sparse: true },
      isAvailable: { type: Boolean, default: true },
      attributes: [{ 
        name: String, 
        value: mongoose.Schema.Types.Mixed 
      }],
      tags: [String]
    }, {
      timestamps: true,
      collection: 'products'
    });
    
    // è®¢å•æ¨¡å¼
    const orderSchema = new mongoose.Schema({
      orderNumber: { type: String, required: true, unique: true },
      user: { type: mongoose.Schema.Types.ObjectId, ref: 'User', required: true },
      items: [{
        product: { type: mongoose.Schema.Types.ObjectId, ref: 'Product', required: true },
        quantity: { type: Number, required: true, min: 1 },
        unitPrice: { type: Number, required: true, min: 0 }
      }],
      status: {
        type: String,
        enum: ['pending', 'confirmed', 'processing', 'shipped', 'delivered', 'cancelled'],
        default: 'pending'
      },
      totalAmount: { type: Number, required: true, min: 0 },
      shippingAddress: {
        street: String,
        city: String,
        state: String,
        zipCode: String,
        country: String
      },
      paymentInfo: {
        method: String,
        transactionId: String,
        paidAt: Date
      }
    }, {
      timestamps: true,
      collection: 'orders'
    });
    
    // åˆ›å»ºæ¨¡å‹
    const User = connection.model('User', userSchema);
    const Product = connection.model('Product', productSchema);
    const Order = connection.model('Order', orderSchema);
    
    // åˆ›å»ºç´¢å¼•
    await User.createIndexes();
    await Product.createIndexes();
    await Order.createIndexes();
    
    // åˆ›å»ºé¢å¤–ç´¢å¼•
    await Product.collection.createIndex({ name: 'text', description: 'text' });
    await Order.collection.createIndex({ 'user': 1, 'createdAt': -1 });
    await Order.collection.createIndex({ 'status': 1, 'createdAt': -1 });
    
    console.log('âœ… MongoDB schema and indexes initialized');
  }
  
  // æ’å…¥æµ‹è¯•æ•°æ®
  async seedTestData(databaseType) {
    const connection = this.connections.get(databaseType);
    
    switch (databaseType) {
      case 'postgresql':
        await this.seedPostgreSQLData(connection);
        break;
      case 'mysql':
        await this.seedMySQLData(connection);
        break;
      case 'mongodb':
        await this.seedMongoDBData(connection);
        break;
      case 'redis':
        await this.seedRedisData(connection);
        break;
    }
  }
  
  async seedPostgreSQLData(pool) {
    // æ’å…¥åˆ†ç±»æ•°æ®
    await pool.query(`
      INSERT INTO categories (name, description) VALUES
      ('Electronics', 'Electronic devices and gadgets'),
      ('Books', 'Physical and digital books'),
      ('Clothing', 'Apparel and accessories')
      ON CONFLICT DO NOTHING
    `);
    
    // æ’å…¥ç”¨æˆ·æ•°æ®
    await pool.query(`
      INSERT INTO users (username, email, password_hash, first_name, last_name) VALUES
      ('john_doe', 'john@test.com', '$2b$10$hash1', 'John', 'Doe'),
      ('jane_smith', 'jane@test.com', '$2b$10$hash2', 'Jane', 'Smith'),
      ('bob_wilson', 'bob@test.com', '$2b$10$hash3', 'Bob', 'Wilson')
      ON CONFLICT DO NOTHING
    `);
    
    // æ’å…¥äº§å“æ•°æ®
    await pool.query(`
      INSERT INTO products (name, description, price, category_id, stock_quantity, sku) VALUES
      ('Laptop Pro', 'High-performance laptop', 1299.99, 1, 10, 'LP001'),
      ('Programming Book', 'Learn Node.js', 49.99, 2, 25, 'PB001'),
      ('T-Shirt', 'Cotton t-shirt', 19.99, 3, 50, 'TS001')
      ON CONFLICT (sku) DO NOTHING
    `);
    
    console.log('âœ… PostgreSQL test data seeded');
  }
  
  async seedMySQLData(connection) {
    // æ’å…¥æµ‹è¯•æ•°æ®çš„MySQLç‰ˆæœ¬
    await connection.execute(`
      INSERT IGNORE INTO categories (name, description) VALUES
      ('Electronics', 'Electronic devices and gadgets'),
      ('Books', 'Physical and digital books'),
      ('Clothing', 'Apparel and accessories')
    `);
    
    await connection.execute(`
      INSERT IGNORE INTO users (username, email, password_hash, first_name, last_name) VALUES
      ('john_doe', 'john@test.com', '$2b$10$hash1', 'John', 'Doe'),
      ('jane_smith', 'jane@test.com', '$2b$10$hash2', 'Jane', 'Smith'),
      ('bob_wilson', 'bob@test.com', '$2b$10$hash3', 'Bob', 'Wilson')
    `);
    
    console.log('âœ… MySQL test data seeded');
  }
  
  async seedMongoDBData(connection) {
    const User = connection.model('User');
    const Product = connection.model('Product');
    
    // æ’å…¥æµ‹è¯•ç”¨æˆ·
    await User.insertMany([
      {
        username: 'john_doe',
        email: 'john@test.com',
        passwordHash: '$2b$10$hash1',
        firstName: 'John',
        lastName: 'Doe'
      },
      {
        username: 'jane_smith',
        email: 'jane@test.com',
        passwordHash: '$2b$10$hash2',
        firstName: 'Jane',
        lastName: 'Smith'
      }
    ]);
    
    // æ’å…¥æµ‹è¯•äº§å“
    await Product.insertMany([
      {
        name: 'Laptop Pro',
        description: 'High-performance laptop',
        price: 1299.99,
        stockQuantity: 10,
        sku: 'LP001'
      },
      {
        name: 'Programming Book',
        description: 'Learn Node.js',
        price: 49.99,
        stockQuantity: 25,
        sku: 'PB001'
      }
    ]);
    
    console.log('âœ… MongoDB test data seeded');
  }
  
  async seedRedisData(client) {
    // è®¾ç½®æµ‹è¯•ç¼“å­˜æ•°æ®
    await client.set('user:1', JSON.stringify({
      id: 1,
      username: 'john_doe',
      email: 'john@test.com'
    }));
    
    await client.set('product:1', JSON.stringify({
      id: 1,
      name: 'Laptop Pro',
      price: 1299.99
    }));
    
    // è®¾ç½®æµ‹è¯•è®¡æ•°å™¨
    await client.set('visit_count', '100');
    
    // è®¾ç½®æµ‹è¯•åˆ—è¡¨
    await client.lpush('recent_orders', '1001', '1002', '1003');
    
    console.log('âœ… Redis test data seeded');
  }
  
  // æ¸…ç†æµ‹è¯•æ•°æ®
  async cleanupTestData(databaseType) {
    const connection = this.connections.get(databaseType);
    
    switch (databaseType) {
      case 'postgresql':
        await this.cleanupPostgreSQLData(connection);
        break;
      case 'mysql':
        await this.cleanupMySQLData(connection);
        break;
      case 'mongodb':
        await this.cleanupMongoDBData(connection);
        break;
      case 'redis':
        await this.cleanupRedisData(connection);
        break;
    }
  }
  
  async cleanupPostgreSQLData(pool) {
    const tables = ['order_items', 'orders', 'products', 'categories', 'users'];
    
    for (const table of tables) {
      await pool.query(`TRUNCATE TABLE ${table} RESTART IDENTITY CASCADE`);
    }
    
    console.log('âœ… PostgreSQL test data cleaned');
  }
  
  async cleanupMySQLData(connection) {
    await connection.execute('SET FOREIGN_KEY_CHECKS = 0');
    
    const tables = ['products', 'categories', 'users'];
    for (const table of tables) {
      await connection.execute(`TRUNCATE TABLE ${table}`);
    }
    
    await connection.execute('SET FOREIGN_KEY_CHECKS = 1');
    
    console.log('âœ… MySQL test data cleaned');
  }
  
  async cleanupMongoDBData(connection) {
    const collections = await connection.db.collections();
    
    for (const collection of collections) {
      await collection.deleteMany({});
    }
    
    console.log('âœ… MongoDB test data cleaned');
  }
  
  async cleanupRedisData(client) {
    await client.flushDb();
    console.log('âœ… Redis test data cleaned');
  }
  
  // å…³é—­æ‰€æœ‰è¿æ¥
  async cleanup() {
    for (const [type, connection] of this.connections) {
      try {
        switch (type) {
          case 'postgresql':
            await connection.end();
            break;
          case 'mysql':
            await connection.end();
            break;
          case 'mongodb':
            await connection.close();
            break;
          case 'redis':
            await connection.quit();
            break;
        }
        console.log(`âœ… ${type} connection closed`);
      } catch (error) {
        console.warn(`âš ï¸  Error closing ${type} connection:`, error.message);
      }
    }
    
    // åœæ­¢MongoDBå†…å­˜æœåŠ¡å™¨
    if (this.mongoServer) {
      await this.mongoServer.stop();
      console.log('âœ… MongoDB memory server stopped');
    }
    
    // æ¸…ç†æµ‹è¯•æ•°æ®åº“
    for (const db of this.testDatabases) {
      if (db.type === 'postgresql' || db.type === 'mysql') {
        try {
          // è¿™é‡Œå¯ä»¥æ·»åŠ åˆ é™¤æµ‹è¯•æ•°æ®åº“çš„é€»è¾‘
          console.log(`âœ… Test database cleanup: ${db.name}`);
        } catch (error) {
          console.warn(`âš ï¸  Error cleaning up database ${db.name}:`, error.message);
        }
      }
    }
    
    this.connections.clear();
    this.testDatabases = [];
  }
}

module.exports = DatabaseTestManager;
```

## ğŸ“ æ•°æ®åº“æµ‹è¯•æœ€ä½³å®è·µ

### æµ‹è¯•æ•°æ®ç®¡ç†ç­–ç•¥

```javascript
const DatabaseTestBestPractices = {
  TEST_DATA_STRATEGY: {
    isolation: [
      'æ¯ä¸ªæµ‹è¯•ä½¿ç”¨ç‹¬ç«‹çš„æ•°æ®é›†',
      'é¿å…æµ‹è¯•é—´çš„æ•°æ®æ±¡æŸ“',
      'ä½¿ç”¨äº‹åŠ¡å›æ»šæ¢å¤çŠ¶æ€',
      'å¹¶è¡Œæµ‹è¯•çš„æ•°æ®éš”ç¦»'
    ],
    
    generation: [
      'ä½¿ç”¨å·¥å‚æ¨¡å¼ç”Ÿæˆæµ‹è¯•æ•°æ®',
      'å»ºç«‹æ•°æ®çš„å±‚æ¬¡å…³ç³»',
      'æ”¯æŒå¤æ‚ä¸šåŠ¡åœºæ™¯',
      'ç¡®ä¿æ•°æ®çš„ä¸€è‡´æ€§'
    ],
    
    lifecycle: [
      'æµ‹è¯•å‰å‡†å¤‡åŸºç¡€æ•°æ®',
      'æµ‹è¯•ä¸­åˆ›å»ºç‰¹å®šæ•°æ®',
      'æµ‹è¯•åæ¸…ç†ä¸´æ—¶æ•°æ®',
      'æ‰¹é‡æ“ä½œæé«˜æ•ˆç‡'
    ]
  },
  
  PERFORMANCE_CONSIDERATIONS: {
    execution: [
      'ä½¿ç”¨å†…å­˜æ•°æ®åº“åŠ é€Ÿæµ‹è¯•',
      'å¹¶è¡Œæ‰§è¡Œç‹¬ç«‹æµ‹è¯•',
      'ä¼˜åŒ–æ•°æ®åº“è¿æ¥ç®¡ç†',
      'å‡å°‘ä¸å¿…è¦çš„æ•°æ®æ“ä½œ'
    ],
    
    monitoring: [
      'ç›‘æ§æµ‹è¯•æ‰§è¡Œæ—¶é—´',
      'åˆ†ææ…¢æŸ¥è¯¢',
      'æ£€æµ‹èµ„æºæ³„æ¼',
      'ä¼˜åŒ–æµ‹è¯•æ•°æ®é‡'
    ]
  },
  
  RELIABILITY_PRACTICES: {
    stability: [
      'ç¡®ä¿æµ‹è¯•çš„å¯é‡å¤æ€§',
      'å¤„ç†å¹¶å‘è®¿é—®å†²çª',
      'éªŒè¯æ•°æ®å®Œæ•´æ€§',
      'æµ‹è¯•å¼‚å¸¸æ¢å¤èƒ½åŠ›'
    ],
    
    maintenance: [
      'å®šæœŸæ›´æ–°æµ‹è¯•æ•°æ®',
      'ä¿æŒæ¶æ„åŒæ­¥',
      'æ–‡æ¡£åŒ–æµ‹è¯•åœºæ™¯',
      'ç›‘æ§æµ‹è¯•è¦†ç›–ç‡'
    ]
  }
};
```

## ğŸ“ æ€»ç»“

æ•°æ®åº“æµ‹è¯•æ˜¯ç¡®ä¿æ•°æ®å±‚å¯é æ€§çš„å…³é”®ç¯èŠ‚ï¼š

- **å…¨é¢è¦†ç›–**ï¼šåŠŸèƒ½ã€æ€§èƒ½ã€å®Œæ•´æ€§ã€å®‰å…¨æ€§æµ‹è¯•
- **ç¯å¢ƒç®¡ç†**ï¼šå¤šæ•°æ®åº“æ”¯æŒã€è‡ªåŠ¨åŒ–ç¯å¢ƒé…ç½®
- **æ•°æ®ç­–ç•¥**ï¼šéš”ç¦»ã€ç”Ÿæˆã€æ¸…ç†çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
- **æ€§èƒ½ä¼˜åŒ–**ï¼šå†…å­˜æ•°æ®åº“ã€å¹¶è¡Œæ‰§è¡Œã€èµ„æºç®¡ç†

é€šè¿‡ç³»ç»ŸåŒ–çš„æ•°æ®åº“æµ‹è¯•ï¼Œå¯ä»¥ç¡®ä¿æ•°æ®è®¿é—®å±‚çš„æ­£ç¡®æ€§å’Œå¯é æ€§ï¼Œä¸ºåº”ç”¨æä¾›ç¨³å›ºçš„æ•°æ®åŸºç¡€ã€‚

## ğŸ”— ç›¸å…³èµ„æº

- [MongoDB Memory Server](https://github.com/nodkz/mongodb-memory-server)
- [Testcontainers Node.js](https://github.com/testcontainers/testcontainers-node)
- [Database Testing Best Practices](https://www.softwaretestinghelp.com/database-testing/)
- [SQL Test Data Management](https://databaserefactoring.com/)
